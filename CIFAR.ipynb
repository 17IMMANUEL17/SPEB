{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86254d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "\n",
      "============================================================\n",
      "Training CNN5 with eta = 1.0\n",
      "============================================================\n",
      "\n",
      "[eta=1.0 Step 0] CosSim: 1.0000 | RelErr: 0.0000\n",
      "[eta=1.0 Step 100] CosSim: 1.0000 | RelErr: 0.0000\n",
      "[eta=1.0 Step 200] CosSim: 1.0000 | RelErr: 0.0007\n",
      "[eta=1.0 Step 300] CosSim: 1.0000 | RelErr: 0.0000\n",
      ">>> Epoch 1 Done | Loss: 1.5839 | TEST ACC: 33.96% | Avg Steps: 11.00\n",
      "[eta=1.0 Step 400] CosSim: 1.0000 | RelErr: 0.0001\n",
      "[eta=1.0 Step 500] CosSim: 1.0000 | RelErr: 0.0007\n",
      "[eta=1.0 Step 600] CosSim: 1.0000 | RelErr: 0.0004\n",
      "[eta=1.0 Step 700] CosSim: 1.0000 | RelErr: 0.0000\n",
      ">>> Epoch 2 Done | Loss: 1.1585 | TEST ACC: 51.43% | Avg Steps: 11.00\n",
      "[eta=1.0 Step 800] CosSim: 1.0000 | RelErr: 0.0004\n",
      "[eta=1.0 Step 900] CosSim: 1.0000 | RelErr: 0.0000\n",
      "[eta=1.0 Step 1000] CosSim: 1.0000 | RelErr: 0.0000\n",
      "[eta=1.0 Step 1100] CosSim: 1.0000 | RelErr: 0.0000\n",
      ">>> Epoch 3 Done | Loss: 0.9951 | TEST ACC: 64.58% | Avg Steps: 11.00\n",
      "[eta=1.0 Step 1200] CosSim: 1.0000 | RelErr: 0.0001\n",
      "[eta=1.0 Step 1300] CosSim: 1.0000 | RelErr: 0.0003\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 464\u001b[39m\n\u001b[32m    461\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFinal Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_acc*\u001b[32m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 413\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    409\u001b[39m y = y.to(device, non_blocking=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    411\u001b[39m lr = cosine_lr(global_step, total_steps, lr_max=lr_max, lr_min=lr_min)\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m gradsW, gradsb, ce, steps_taken = \u001b[43mxz_relax_batch_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[43m=\u001b[49m\u001b[43meta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m=\u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    415\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[38;5;66;03m# --- COMPARISON LOGIC (Preserved) ---\u001b[39;00m\n\u001b[32m    418\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_step % compare_every == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 99\u001b[39m, in \u001b[36mxz_relax_batch_grad\u001b[39m\u001b[34m(net, x0, y, eta, K, state, tol, warm_start, beta)\u001b[39m\n\u001b[32m     96\u001b[39m m4 = (x4 + z4) * \u001b[32m0.5\u001b[39m; s4 = (x4 - z4)\n\u001b[32m     97\u001b[39m m5 = (x5 + z5) * \u001b[32m0.5\u001b[39m; s5 = (x5 - z5)\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m (u1, sig1), (u2, sig2), (u3, sig3), (u4, sig4), (u5, sig5) = \u001b[43mforward_u_sig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm4\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m F1 = sig1 - m1; F2 = sig2 - m2\n\u001b[32m    102\u001b[39m F3 = sig3 - m3; F4 = sig4 - m4; F5 = sig5 - m5\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mforward_u_sig\u001b[39m\u001b[34m(net, x0, m1, m2, m3, m4)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;129m@torch\u001b[39m.no_grad()\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward_u_sig\u001b[39m(net: CNN5, x0, m1, m2, m3, m4):\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     u1 = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mW1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m; sig1 = relu(u1)\n\u001b[32m     40\u001b[39m     u2 = F.conv2d(m1, net.W2, net.b2, stride=\u001b[32m2\u001b[39m, padding=\u001b[32m1\u001b[39m); sig2 = relu(u2)\n\u001b[32m     41\u001b[39m     u3 = F.conv2d(m2, net.W3, net.b3, stride=\u001b[32m1\u001b[39m, padding=\u001b[32m1\u001b[39m); sig3 = relu(u3)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from dataclasses import dataclass\n",
    "from torch.nn.grad import conv2d_weight\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "# -----------------------------\n",
    "# Activations\n",
    "# -----------------------------\n",
    "def relu(u): return torch.relu(u)\n",
    "def relu_prime(u): return (u > 0).to(u.dtype)\n",
    "\n",
    "# -----------------------------\n",
    "# Model container (4 Conv + 1 FC = 5 Layers)\n",
    "# \"VGG-Style\": 64 -> 128 -> 256 -> 512\n",
    "# -----------------------------\n",
    "@dataclass\n",
    "class CNN5:\n",
    "    W1: torch.Tensor; b1: torch.Tensor   # (64, 3, 3, 3)\n",
    "    W2: torch.Tensor; b2: torch.Tensor   # (128, 64, 3, 3)\n",
    "    W3: torch.Tensor; b3: torch.Tensor   # (256, 128, 3, 3)\n",
    "    W4: torch.Tensor; b4: torch.Tensor   # (512, 256, 3, 3)\n",
    "    W5: torch.Tensor; b5: torch.Tensor   # (10, 512*8*8)\n",
    "\n",
    "    @property\n",
    "    def device(self): return self.W1.device\n",
    "\n",
    "# -----------------------------\n",
    "# Forward at mean states\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def forward_u_sig(net: CNN5, x0, m1, m2, m3, m4):\n",
    "    u1 = F.conv2d(x0, net.W1, net.b1, stride=1, padding=1); sig1 = relu(u1)\n",
    "    u2 = F.conv2d(m1, net.W2, net.b2, stride=2, padding=1); sig2 = relu(u2)\n",
    "    u3 = F.conv2d(m2, net.W3, net.b3, stride=1, padding=1); sig3 = relu(u3)\n",
    "    u4 = F.conv2d(m3, net.W4, net.b4, stride=2, padding=1); sig4 = relu(u4)\n",
    "    \n",
    "    B = x0.shape[0]\n",
    "    m4_flat = m4.reshape(B, -1) \n",
    "    u5 = m4_flat @ net.W5.t() + net.b5\n",
    "    sig5 = u5\n",
    "\n",
    "    return (u1, sig1), (u2, sig2), (u3, sig3), (u4, sig4), (u5, sig5)\n",
    "\n",
    "class XZState:\n",
    "    def __init__(self):\n",
    "        self.x1 = None; self.z1 = None\n",
    "        self.x2 = None; self.z2 = None\n",
    "        self.x3 = None; self.z3 = None\n",
    "        self.x4 = None; self.z4 = None\n",
    "        self.x5 = None; self.z5 = None\n",
    "\n",
    "# -----------------------------\n",
    "# Hamiltonian x-z relaxation gradient for batch (CNN)\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def xz_relax_batch_grad(\n",
    "    net: CNN5, x0, y,\n",
    "    eta=1.0, K=30,\n",
    "    state: XZState | None = None,\n",
    "    tol: float = 1e-4,\n",
    "    warm_start: bool = True,\n",
    "    beta: float = 1.0,\n",
    "):\n",
    "    device = net.device\n",
    "    B = x0.shape[0]\n",
    "    y_onehot = F.one_hot(y, num_classes=10).to(x0.dtype)\n",
    "\n",
    "    def alloc():\n",
    "        x1 = torch.zeros(B, 64, 32, 32, device=device); z1 = torch.zeros_like(x1)\n",
    "        x2 = torch.zeros(B, 128, 16, 16, device=device); z2 = torch.zeros_like(x2)\n",
    "        x3 = torch.zeros(B, 256, 16, 16, device=device); z3 = torch.zeros_like(x3)\n",
    "        x4 = torch.zeros(B, 512, 8, 8, device=device);   z4 = torch.zeros_like(x4)\n",
    "        x5 = torch.zeros(B, 10, device=device);          z5 = torch.zeros_like(x5)\n",
    "        return x1,z1,x2,z2,x3,z3,x4,z4,x5,z5\n",
    "\n",
    "    if (state is None) or (not warm_start) or (state.x1 is None) or (state.x1.shape[0] != B):\n",
    "        x1,z1,x2,z2,x3,z3,x4,z4,x5,z5 = alloc()\n",
    "        if state is not None:\n",
    "            state.x1,state.z1,state.x2,state.z2,state.x3,state.z3,state.x4,state.z4,state.x5,state.z5 = x1,z1,x2,z2,x3,z3,x4,z4,x5,z5\n",
    "    else:\n",
    "        x1,z1,x2,z2,x3,z3,x4,z4,x5,z5 = state.x1,state.z1,state.x2,state.z2,state.x3,state.z3,state.x4,state.z4,state.x5,state.z5\n",
    "\n",
    "    steps_taken = 0\n",
    "    for _ in range(K):\n",
    "        steps_taken += 1\n",
    "        m1 = (x1 + z1) * 0.5; s1 = (x1 - z1)\n",
    "        m2 = (x2 + z2) * 0.5; s2 = (x2 - z2)\n",
    "        m3 = (x3 + z3) * 0.5; s3 = (x3 - z3)\n",
    "        m4 = (x4 + z4) * 0.5; s4 = (x4 - z4)\n",
    "        m5 = (x5 + z5) * 0.5; s5 = (x5 - z5)\n",
    "\n",
    "        (u1, sig1), (u2, sig2), (u3, sig3), (u4, sig4), (u5, sig5) = forward_u_sig(net, x0, m1, m2, m3, m4)\n",
    "\n",
    "        F1 = sig1 - m1; F2 = sig2 - m2\n",
    "        F3 = sig3 - m3; F4 = sig4 - m4; F5 = sig5 - m5\n",
    "\n",
    "        p = torch.softmax(m5, dim=1)\n",
    "        g5 = (p - y_onehot)\n",
    "\n",
    "        q2 = relu_prime(u2) * s2\n",
    "        q3 = relu_prime(u3) * s3\n",
    "        q4 = relu_prime(u4) * s4\n",
    "        q5 = s5\n",
    "\n",
    "        WTq4 = (q5 @ net.W5).reshape(B, 512, 8, 8)\n",
    "        WTq3 = F.conv_transpose2d(q4, net.W4, bias=None, stride=2, padding=1, output_padding=1)\n",
    "        WTq2 = F.conv_transpose2d(q3, net.W3, bias=None, stride=1, padding=1)\n",
    "        WTq1 = F.conv_transpose2d(q2, net.W2, bias=None, stride=2, padding=1, output_padding=1)\n",
    "\n",
    "        Jt1 = -s1 + WTq1; Jt2 = -s2 + WTq2\n",
    "        Jt3 = -s3 + WTq3; Jt4 = -s4 + WTq4; Jt5 = -s5\n",
    "\n",
    "        dx1 = F1 + 0.5 * Jt1; dz1 = F1 - 0.5 * Jt1\n",
    "        dx2 = F2 + 0.5 * Jt2; dz2 = F2 - 0.5 * Jt2\n",
    "        dx3 = F3 + 0.5 * Jt3; dz3 = F3 - 0.5 * Jt3\n",
    "        dx4 = F4 + 0.5 * Jt4; dz4 = F4 - 0.5 * Jt4\n",
    "        dx5 = F5 + 0.5 * Jt5 + 0.5 * beta * g5\n",
    "        dz5 = F5 - 0.5 * Jt5 - 0.5 * beta * g5\n",
    "\n",
    "        x1.add_(dx1, alpha=eta); z1.add_(dz1, alpha=eta)\n",
    "        x2.add_(dx2, alpha=eta); z2.add_(dz2, alpha=eta)\n",
    "        x3.add_(dx3, alpha=eta); z3.add_(dz3, alpha=eta)\n",
    "        x4.add_(dx4, alpha=eta); z4.add_(dz4, alpha=eta)\n",
    "        x5.add_(dx5, alpha=eta); z5.add_(dz5, alpha=eta)\n",
    "\n",
    "        upd = (dx1.abs().mean() + dx2.abs().mean() + dx3.abs().mean() + dx4.abs().mean() + dx5.abs().mean()).item()\n",
    "        if upd < tol:\n",
    "            break\n",
    "\n",
    "    if state is not None and warm_start:\n",
    "        state.x1,state.z1,state.x2,state.z2,state.x3,state.z3,state.x4,state.z4,state.x5,state.z5 = x1,z1,x2,z2,x3,z3,x4,z4,x5,z5\n",
    "\n",
    "    m1 = (x1 + z1) * 0.5; s1 = (x1 - z1)\n",
    "    m2 = (x2 + z2) * 0.5; s2 = (x2 - z2)\n",
    "    m3 = (x3 + z3) * 0.5; s3 = (x3 - z3)\n",
    "    m4 = (x4 + z4) * 0.5; s4 = (x4 - z4)\n",
    "\n",
    "    (u1, _), (u2, _), (u3, _), (u4, _), (_, _) = forward_u_sig(net, x0, m1, m2, m3, m4)\n",
    "\n",
    "    delta1 = relu_prime(u1) * s1; delta2 = relu_prime(u2) * s2\n",
    "    delta3 = relu_prime(u3) * s3; delta4 = relu_prime(u4) * s4; delta5 = s5\n",
    "\n",
    "    dW1 = conv2d_weight(x0, net.W1.shape, delta1, stride=1, padding=1) / B\n",
    "    dW2 = conv2d_weight(m1, net.W2.shape, delta2, stride=2, padding=1) / B\n",
    "    dW3 = conv2d_weight(m2, net.W3.shape, delta3, stride=1, padding=1) / B\n",
    "    dW4 = conv2d_weight(m3, net.W4.shape, delta4, stride=2, padding=1) / B\n",
    "    m4_flat = m4.reshape(B, -1)\n",
    "    dW5 = (delta5.t() @ m4_flat) / B\n",
    "\n",
    "    db1 = delta1.sum(dim=(0,2,3)) / B; db2 = delta2.sum(dim=(0,2,3)) / B\n",
    "    db3 = delta3.sum(dim=(0,2,3)) / B; db4 = delta4.sum(dim=(0,2,3)) / B\n",
    "    db5 = delta5.mean(dim=0)\n",
    "\n",
    "    ce = F.cross_entropy(m5, y).item()\n",
    "    return (dW1,dW2,dW3,dW4,dW5), (db1,db2,db3,db4,db5), ce, steps_taken\n",
    "\n",
    "# -----------------------------\n",
    "# SGD + momentum\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def sgd_momentum_step(net: CNN5, gradsW, gradsb, vW, vb,\n",
    "                      lr=0.01, momentum=0.9, weight_decay=1e-4, clip=1.0):\n",
    "    for i in range(5):\n",
    "        dWi = gradsW[i] + weight_decay * getattr(net, f\"W{i+1}\")\n",
    "        dbi = gradsb[i]\n",
    "        \n",
    "        gn = (dWi.norm()**2 + dbi.norm()**2)**0.5\n",
    "        scale = 1.0 if gn <= clip else (clip / (gn + 1e-12))\n",
    "        dWi *= scale; dbi *= scale\n",
    "\n",
    "        vW[i].mul_(momentum).add_(dWi)\n",
    "        vb[i].mul_(momentum).add_(dbi)\n",
    "\n",
    "        getattr(net, f\"W{i+1}\").sub_(lr * vW[i])\n",
    "        getattr(net, f\"b{i+1}\").sub_(lr * vb[i])\n",
    "\n",
    "@torch.no_grad()\n",
    "def ema_update(ema_net: CNN5, net: CNN5, decay=0.999):\n",
    "    for i in range(1, 6):\n",
    "        for param in [\"W\", \"b\"]:\n",
    "            name = f\"{param}{i}\"\n",
    "            getattr(ema_net, name).mul_(decay).add_(getattr(net, name), alpha=(1.0 - decay))\n",
    "\n",
    "@torch.no_grad()\n",
    "def accuracy(net: CNN5, loader, device, max_batches=800):\n",
    "    correct = 0; total = 0\n",
    "    for i, (x,y) in enumerate(loader):\n",
    "        if i >= max_batches: break\n",
    "        x = x.to(device); y = y.to(device)\n",
    "        h1 = relu(F.conv2d(x, net.W1, net.b1, stride=1, padding=1))\n",
    "        h2 = relu(F.conv2d(h1, net.W2, net.b2, stride=2, padding=1))\n",
    "        h3 = relu(F.conv2d(h2, net.W3, net.b3, stride=1, padding=1))\n",
    "        h4 = relu(F.conv2d(h3, net.W4, net.b4, stride=2, padding=1))\n",
    "        logits = h4.reshape(x.size(0), -1) @ net.W5.t() + net.b5\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.numel()\n",
    "    return correct / max(1, total)\n",
    "\n",
    "def cosine_lr(step, total_steps, lr_max=0.05, lr_min=5e-4):\n",
    "    t = step / max(1, total_steps)\n",
    "    return lr_min + 0.5*(lr_max - lr_min)*(1.0 + math.cos(math.pi * t))\n",
    "\n",
    "def kaiming_init(shape, device):\n",
    "    fan_in = (shape[1] * shape[2] * shape[3]) if len(shape) == 4 else shape[1]\n",
    "    return math.sqrt(2.0 / fan_in) * torch.randn(shape, device=device)\n",
    "\n",
    "# -----------------------------\n",
    "# Autograd Reference\n",
    "# -----------------------------\n",
    "def autograd_grads_like_cnn5(net: CNN5, x, y):\n",
    "    params = {}\n",
    "    for i in range(1, 6):\n",
    "        params[f\"W{i}\"] = getattr(net, f\"W{i}\").detach().clone().requires_grad_(True)\n",
    "        params[f\"b{i}\"] = getattr(net, f\"b{i}\").detach().clone().requires_grad_(True)\n",
    "    \n",
    "    h1 = relu(F.conv2d(x, params['W1'], params['b1'], stride=1, padding=1))\n",
    "    h2 = relu(F.conv2d(h1, params['W2'], params['b2'], stride=2, padding=1))\n",
    "    h3 = relu(F.conv2d(h2, params['W3'], params['b3'], stride=1, padding=1))\n",
    "    h4 = relu(F.conv2d(h3, params['W4'], params['b4'], stride=2, padding=1))\n",
    "    logits = h4.reshape(x.size(0), -1) @ params['W5'].t() + params['b5']\n",
    "    \n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    loss.backward()\n",
    "    \n",
    "    gradsW = tuple(params[f\"W{i}\"].grad for i in range(1, 6))\n",
    "    gradsb = tuple(params[f\"b{i}\"].grad for i in range(1, 6))\n",
    "    return gradsW, gradsb, float(loss.detach())\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics\n",
    "# -----------------------------\n",
    "def flat_cat(tup):\n",
    "    return torch.cat([t.reshape(-1) for t in tup], dim=0)\n",
    "\n",
    "def cos_sim(a, b, eps=1e-12):\n",
    "    denom = (a.norm() * b.norm()).clamp_min(eps)\n",
    "    return float((a @ b) / denom)\n",
    "\n",
    "def relative_error(a, b, eps=1e-12):\n",
    "    return float((a - b).norm() / b.norm().clamp_min(eps))\n",
    "\n",
    "# -----------------------------\n",
    "# Plotting Functions\n",
    "# -----------------------------\n",
    "def set_style():\n",
    "    mpl.rcParams.update({\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.serif\": [\"Times New Roman\", \"DejaVu Serif\"],\n",
    "        \"font.size\": 14,\n",
    "        \"axes.labelsize\": 16,\n",
    "        \"axes.titlesize\": 18,\n",
    "        \"xtick.labelsize\": 14,\n",
    "        \"ytick.labelsize\": 14,\n",
    "        \"legend.fontsize\": 14,\n",
    "        \"lines.linewidth\": 2.5,\n",
    "        \"lines.markersize\": 8,\n",
    "        \"figure.figsize\": (8, 6),\n",
    "        \"text.usetex\": False,\n",
    "    })\n",
    "\n",
    "def plot_results_icml(results, eta_values):\n",
    "    \"\"\"Plots Gradient Fidelity (Relative Error)\"\"\"\n",
    "    set_style()\n",
    "    plt.figure()\n",
    "    \n",
    "    styles = {\n",
    "        0.8: {'color': '#d62728', 'marker': 'o', 'linestyle': '-'},\n",
    "        1.0: {'color': '#1f77b4', 'marker': 's', 'linestyle': '--'},\n",
    "        1.2: {'color': '#2ca02c', 'marker': '^', 'linestyle': '-.'},\n",
    "    }\n",
    "\n",
    "    for eta in eta_values:\n",
    "        if eta not in results: continue\n",
    "        data = results[eta]\n",
    "        cos_steps = data['cos_steps']\n",
    "        rel_err = data['relerr_globalW_hist']\n",
    "        \n",
    "        if len(cos_steps) == 0: continue\n",
    "        style = styles.get(eta, {'color': 'black', 'marker': 'x', 'linestyle': ':'})\n",
    "        \n",
    "        plt.plot(cos_steps, rel_err, \n",
    "                 label=fr'$\\eta={eta}$', \n",
    "                 color=style['color'], \n",
    "                 marker=style['marker'], \n",
    "                 linestyle=style['linestyle'])\n",
    "\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Training Steps')\n",
    "    plt.ylabel(r'Relative Grad Error $\\frac{||\\nabla_{xz} - \\nabla_{BP}||}{||\\nabla_{BP}||}$')\n",
    "    plt.title('Gradient Fidelity (5-Layer VGG-Style)')\n",
    "    plt.grid(True, which=\"both\", ls=\":\", alpha=0.6)\n",
    "    plt.legend(frameon=True, fancybox=False, edgecolor='k')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('cnn5_grad_fidelity.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"Fidelity plot saved to: cnn5_grad_fidelity.png\")\n",
    "\n",
    "def plot_convergence_icml(results, eta_values):\n",
    "    \"\"\"Plots Average Convergence Steps per Epoch\"\"\"\n",
    "    set_style()\n",
    "    plt.figure()\n",
    "\n",
    "    styles = {\n",
    "        0.8: {'color': '#d62728', 'marker': 'o', 'linestyle': '-'},\n",
    "        1.0: {'color': '#1f77b4', 'marker': 's', 'linestyle': '--'},\n",
    "        1.2: {'color': '#2ca02c', 'marker': '^', 'linestyle': '-.'},\n",
    "    }\n",
    "\n",
    "    for eta in eta_values:\n",
    "        if eta not in results: continue\n",
    "        data = results[eta]\n",
    "        # We stored the list of avg steps per epoch here\n",
    "        avg_steps = data['avg_steps_per_epoch']\n",
    "        epochs = range(1, len(avg_steps) + 1)\n",
    "\n",
    "        style = styles.get(eta, {'color': 'black', 'marker': 'x', 'linestyle': ':'})\n",
    "\n",
    "        plt.plot(epochs, avg_steps,\n",
    "                 label=fr'$\\eta={eta}$',\n",
    "                 color=style['color'],\n",
    "                 marker=style['marker'],\n",
    "                 linestyle=style['linestyle'])\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Avg. Convergence Steps ($K$)')\n",
    "    plt.title('Relaxation Convergence Speed')\n",
    "    plt.grid(True, which=\"both\", ls=\":\", alpha=0.6)\n",
    "    plt.legend(frameon=True, fancybox=False, edgecolor='k')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('cnn5_convergence_steps.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"Convergence plot saved to: cnn5_convergence_steps.png\")\n",
    "\n",
    "# -----------------------------\n",
    "# Main\n",
    "# -----------------------------\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"device:\", device)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    cifar_mean = (0.4914, 0.4822, 0.4465)\n",
    "    cifar_std  = (0.2470, 0.2435, 0.2616)\n",
    "    train_tfm = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(cifar_mean, cifar_std)\n",
    "    ])\n",
    "    test_tfm = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(cifar_mean, cifar_std)\n",
    "    ])\n",
    "    \n",
    "    train_ds = datasets.CIFAR10(\"./data\", train=True, download=True, transform=train_tfm)\n",
    "    test_ds  = datasets.CIFAR10(\"./data\", train=False, download=True, transform=test_tfm)\n",
    "    train_loader = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    test_loader  = DataLoader(test_ds, batch_size=256, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    epochs = 20\n",
    "    K = 25\n",
    "    lr_max = 0.05\n",
    "    lr_min = 0.0005\n",
    "    \n",
    "    eta_values = [1.0] # Add more here like [0.8, 1.0, 1.2] for comparison\n",
    "    compare_every = 100\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    for eta in eta_values:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Training CNN5 with eta = {eta}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        torch.manual_seed(42)\n",
    "        W1 = kaiming_init((64, 3, 3, 3), device); b1 = torch.zeros(64, device=device)\n",
    "        W2 = kaiming_init((128, 64, 3, 3), device); b2 = torch.zeros(128, device=device)\n",
    "        W3 = kaiming_init((256, 128, 3, 3), device); b3 = torch.zeros(256, device=device)\n",
    "        W4 = kaiming_init((512, 256, 3, 3), device); b4 = torch.zeros(512, device=device)\n",
    "        W5 = kaiming_init((10, 512*8*8), device); b5 = torch.zeros(10, device=device)\n",
    "\n",
    "        net = CNN5(W1,b1,W2,b2,W3,b3,W4,b4,W5,b5)\n",
    "        ema_net = CNN5(W1.clone(),b1.clone(),W2.clone(),b2.clone(),W3.clone(),b3.clone(),W4.clone(),b4.clone(),W5.clone(),b5.clone())\n",
    "        vW = [torch.zeros_like(getattr(net, f\"W{i}\")) for i in range(1,6)]\n",
    "        vb = [torch.zeros_like(getattr(net, f\"b{i}\")) for i in range(1,6)]\n",
    "\n",
    "        total_steps = epochs * len(train_loader)\n",
    "        global_step = 0\n",
    "        state = XZState()\n",
    "        \n",
    "        cos_globalW_hist = []\n",
    "        relerr_globalW_hist = []\n",
    "        cos_steps = []\n",
    "        avg_steps_per_epoch = []\n",
    "\n",
    "        for ep in range(1, epochs+1):\n",
    "            running_ce = 0.0\n",
    "            epoch_steps_accum = 0\n",
    "            num_batches = 0\n",
    "            \n",
    "            for i, (x, y) in enumerate(train_loader):\n",
    "                x = x.to(device, non_blocking=True)\n",
    "                y = y.to(device, non_blocking=True)\n",
    "\n",
    "                lr = cosine_lr(global_step, total_steps, lr_max=lr_max, lr_min=lr_min)\n",
    "\n",
    "                gradsW, gradsb, ce, steps_taken = xz_relax_batch_grad(\n",
    "                    net, x, y, eta=eta, K=K, state=state, warm_start=True\n",
    "                )\n",
    "                \n",
    "                # --- COMPARISON LOGIC (Preserved) ---\n",
    "                if global_step % compare_every == 0:\n",
    "                    gradsW_ag, _, _ = autograd_grads_like_cnn5(net, x, y)\n",
    "                    gx = flat_cat(gradsW)\n",
    "                    ga = flat_cat(gradsW_ag)\n",
    "                    c_sim = cos_sim(gx, ga)\n",
    "                    r_err = relative_error(gx, ga)\n",
    "                    cos_globalW_hist.append(c_sim)\n",
    "                    relerr_globalW_hist.append(r_err)\n",
    "                    cos_steps.append(global_step)\n",
    "                    print(f\"[eta={eta} Step {global_step}] CosSim: {c_sim:.4f} | RelErr: {r_err:.4f}\")\n",
    "\n",
    "                sgd_momentum_step(net, gradsW, gradsb, vW, vb, lr=lr)\n",
    "                ema_update(ema_net, net)\n",
    "\n",
    "                global_step += 1\n",
    "                running_ce += ce\n",
    "                epoch_steps_accum += steps_taken\n",
    "                num_batches += 1\n",
    "\n",
    "            # End of Epoch Metrics\n",
    "            test_acc = accuracy(ema_net, test_loader, device)\n",
    "            train_loss_avg = running_ce / len(train_loader)\n",
    "            avg_k = epoch_steps_accum / num_batches\n",
    "            avg_steps_per_epoch.append(avg_k)\n",
    "\n",
    "            print(f\">>> Epoch {ep} Done | Loss: {train_loss_avg:.4f} | TEST ACC: {test_acc*100:.2f}% | Avg Steps: {avg_k:.2f}\")\n",
    "\n",
    "        results[eta] = {\n",
    "            'cos_globalW_hist': cos_globalW_hist,\n",
    "            'relerr_globalW_hist': relerr_globalW_hist,\n",
    "            'cos_steps': cos_steps,\n",
    "            'avg_steps_per_epoch': avg_steps_per_epoch\n",
    "        }\n",
    "\n",
    "    print(\"Training Complete. Generating Plots...\")\n",
    "    \n",
    "    # 1. Original Fidelity Plot\n",
    "    plot_results_icml(results, eta_values)\n",
    "    \n",
    "    # 2. New Convergence Steps Plot (Same Style)\n",
    "    plot_convergence_icml(results, eta_values)\n",
    "    \n",
    "    final_acc = accuracy(ema_net, test_loader, device, max_batches=2000)\n",
    "    print(f\"Final Test Accuracy: {final_acc*100:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91629e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training CNN9 (eta=1.0)...\n",
      "[Step 0] CosSim: 1.0000 | RelErr: 0.0006\n",
      "[Step 100] CosSim: 1.0000 | RelErr: 0.0029\n",
      "[Step 200] CosSim: 1.0000 | RelErr: 0.0049\n",
      "[Step 300] CosSim: 1.0000 | RelErr: 0.0022\n",
      "[Step 400] CosSim: 1.0000 | RelErr: 0.0009\n",
      "[Step 500] CosSim: 1.0000 | RelErr: 0.0040\n",
      "[Step 600] CosSim: 1.0000 | RelErr: 0.0028\n",
      "[Step 700] CosSim: 1.0000 | RelErr: 0.0011\n",
      ">>> Ep 1: Loss 1.7033 | ACC 32.57% | Avg K: 19.0\n",
      "[Step 800] CosSim: 1.0000 | RelErr: 0.0001\n",
      "[Step 900] CosSim: 1.0000 | RelErr: 0.0021\n",
      "[Step 1000] CosSim: 1.0000 | RelErr: 0.0002\n",
      "[Step 1100] CosSim: 1.0000 | RelErr: 0.0006\n",
      "[Step 1200] CosSim: 1.0000 | RelErr: 0.0046\n",
      "[Step 1300] CosSim: 1.0000 | RelErr: 0.0010\n",
      "[Step 1400] CosSim: 1.0000 | RelErr: 0.0001\n",
      "[Step 1500] CosSim: 1.0000 | RelErr: 0.0006\n",
      ">>> Ep 2: Loss 1.3643 | ACC 47.76% | Avg K: 19.0\n",
      "[Step 1600] CosSim: 1.0000 | RelErr: 0.0025\n",
      "[Step 1700] CosSim: 1.0000 | RelErr: 0.0009\n",
      "[Step 1800] CosSim: 1.0000 | RelErr: 0.0010\n",
      "[Step 1900] CosSim: 1.0000 | RelErr: 0.0004\n",
      "[Step 2000] CosSim: 1.0000 | RelErr: 0.0009\n",
      "[Step 2100] CosSim: 1.0000 | RelErr: 0.0003\n",
      "[Step 2200] CosSim: 1.0000 | RelErr: 0.0009\n",
      "[Step 2300] CosSim: 1.0000 | RelErr: 0.0008\n",
      ">>> Ep 3: Loss 1.1823 | ACC 55.85% | Avg K: 19.0\n",
      "[Step 2400] CosSim: 1.0000 | RelErr: 0.0001\n",
      "[Step 2500] CosSim: 1.0000 | RelErr: 0.0001\n",
      "[Step 2600] CosSim: 1.0000 | RelErr: 0.0005\n",
      "[Step 2700] CosSim: 1.0000 | RelErr: 0.0002\n",
      "[Step 2800] CosSim: 1.0000 | RelErr: 0.0023\n",
      "[Step 2900] CosSim: 1.0000 | RelErr: 0.0002\n",
      "[Step 3000] CosSim: 1.0000 | RelErr: 0.0004\n",
      "[Step 3100] CosSim: 1.0000 | RelErr: 0.0004\n",
      ">>> Ep 4: Loss 1.0496 | ACC 63.02% | Avg K: 19.0\n",
      "[Step 3200] CosSim: 1.0000 | RelErr: 0.0001\n",
      "[Step 3300] CosSim: 1.0000 | RelErr: 0.0019\n",
      "[Step 3400] CosSim: 1.0000 | RelErr: 0.0001\n",
      "[Step 3500] CosSim: 1.0000 | RelErr: 0.0005\n",
      "[Step 3600] CosSim: 1.0000 | RelErr: 0.0001\n",
      "[Step 3700] CosSim: 1.0000 | RelErr: 0.0001\n",
      "[Step 3800] CosSim: 1.0000 | RelErr: 0.0002\n",
      "[Step 3900] CosSim: 1.0000 | RelErr: 0.0001\n",
      ">>> Ep 5: Loss 0.9585 | ACC 68.32% | Avg K: 19.0\n",
      "[Step 4000] CosSim: 1.0000 | RelErr: 0.0001\n",
      "[Step 4100] CosSim: 1.0000 | RelErr: 0.0003\n",
      "[Step 4200] CosSim: 1.0000 | RelErr: 0.0014\n",
      "[Step 4300] CosSim: 1.0000 | RelErr: 0.0001\n",
      "[Step 4400] CosSim: 1.0000 | RelErr: 0.0001\n",
      "[Step 4500] CosSim: 1.0000 | RelErr: 0.0001\n",
      "[Step 4600] CosSim: 1.0000 | RelErr: 0.0002\n",
      ">>> Ep 6: Loss 0.8799 | ACC 72.71% | Avg K: 19.0\n",
      "[Step 4700] CosSim: 1.0000 | RelErr: 0.0001\n",
      "[Step 4800] CosSim: 1.0000 | RelErr: 0.0002\n",
      "[Step 4900] CosSim: 1.0000 | RelErr: 0.0003\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 535\u001b[39m\n\u001b[32m    532\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFinal Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_acc*\u001b[32m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 487\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    484\u001b[39m y = y.to(device, non_blocking=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    485\u001b[39m lr = cosine_lr(global_step, total_steps, lr_max=lr_max, lr_min=lr_min)\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m gradsW, gradsb, ce, steps_taken = \u001b[43mxz_relax_batch_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[43m=\u001b[49m\u001b[43meta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m=\u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    489\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: state = XZState(x.shape[\u001b[32m0\u001b[39m], device)\n\u001b[32m    492\u001b[39m \u001b[38;5;66;03m# Fidelity Check\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 159\u001b[39m, in \u001b[36mxz_relax_batch_grad\u001b[39m\u001b[34m(net, x0, y, eta, K, state, tol, warm_start, beta)\u001b[39m\n\u001b[32m    157\u001b[39m Jt[\u001b[32m3\u001b[39m] = -s[\u001b[32m3\u001b[39m] + F.conv_transpose2d(q[\u001b[32m4\u001b[39m], net.W5, stride=\u001b[32m1\u001b[39m, padding=\u001b[32m1\u001b[39m)\n\u001b[32m    158\u001b[39m Jt[\u001b[32m2\u001b[39m] = -s[\u001b[32m2\u001b[39m] + F.conv_transpose2d(q[\u001b[32m3\u001b[39m], net.W4, stride=\u001b[32m2\u001b[39m, padding=\u001b[32m1\u001b[39m, output_padding=\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m Jt[\u001b[32m1\u001b[39m] = -s[\u001b[32m1\u001b[39m] + \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv_transpose2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mW3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m Jt[\u001b[32m0\u001b[39m] = -s[\u001b[32m0\u001b[39m] + F.conv_transpose2d(q[\u001b[32m1\u001b[39m], net.W2, stride=\u001b[32m2\u001b[39m, padding=\u001b[32m1\u001b[39m, output_padding=\u001b[32m1\u001b[39m)\n\u001b[32m    162\u001b[39m total_change = \u001b[32m0.0\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from dataclasses import dataclass\n",
    "from torch.nn.grad import conv2d_weight\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "# -----------------------------\n",
    "# Activations (BN REMOVED to restore Fidelity)\n",
    "# -----------------------------\n",
    "def relu(u): return torch.relu(u)\n",
    "def relu_prime(u): return (u > 0).to(u.dtype)\n",
    "\n",
    "# -----------------------------\n",
    "# Model container (8 Conv + 1 FC = 9 Layers)\n",
    "# Structure: [64-64] -> [128-128] -> [256-256] -> [512-512] -> Linear\n",
    "# -----------------------------\n",
    "@dataclass\n",
    "class CNN9:\n",
    "    # Block 1: 32x32 -> 16x16\n",
    "    W1: torch.Tensor; b1: torch.Tensor   # (64, 3, 3, 3)   s=1\n",
    "    W2: torch.Tensor; b2: torch.Tensor   # (64, 64, 3, 3)  s=2 (pool)\n",
    "    \n",
    "    # Block 2: 16x16 -> 8x8\n",
    "    W3: torch.Tensor; b3: torch.Tensor   # (128, 64, 3, 3) s=1\n",
    "    W4: torch.Tensor; b4: torch.Tensor   # (128, 128, 3, 3) s=2 (pool)\n",
    "    \n",
    "    # Block 3: 8x8 -> 4x4\n",
    "    W5: torch.Tensor; b5: torch.Tensor   # (256, 128, 3, 3) s=1\n",
    "    W6: torch.Tensor; b6: torch.Tensor   # (256, 256, 3, 3) s=2 (pool)\n",
    "    \n",
    "    # Block 4: 4x4 -> 2x2\n",
    "    W7: torch.Tensor; b7: torch.Tensor   # (512, 256, 3, 3) s=1\n",
    "    W8: torch.Tensor; b8: torch.Tensor   # (512, 512, 3, 3) s=2 (pool)\n",
    "    \n",
    "    # Classifier: 2x2 -> Flat\n",
    "    W9: torch.Tensor; b9: torch.Tensor   # (10, 512*2*2)\n",
    "\n",
    "    @property\n",
    "    def device(self): return self.W1.device\n",
    "\n",
    "# -----------------------------\n",
    "# Forward at mean states (Standard Conv -> ReLU)\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def forward_u_sig(net: CNN9, x0, m):\n",
    "    # m is a list of [m1, m2, ..., m8]\n",
    "    u = [None] * 9\n",
    "    sig = [None] * 9\n",
    "    \n",
    "    # Block 1\n",
    "    u[0] = F.conv2d(x0, net.W1, net.b1, stride=1, padding=1);   sig[0] = relu(u[0])\n",
    "    u[1] = F.conv2d(m[0], net.W2, net.b2, stride=2, padding=1); sig[1] = relu(u[1])\n",
    "    \n",
    "    # Block 2\n",
    "    u[2] = F.conv2d(m[1], net.W3, net.b3, stride=1, padding=1); sig[2] = relu(u[2])\n",
    "    u[3] = F.conv2d(m[2], net.W4, net.b4, stride=2, padding=1); sig[3] = relu(u[3])\n",
    "    \n",
    "    # Block 3\n",
    "    u[4] = F.conv2d(m[3], net.W5, net.b5, stride=1, padding=1); sig[4] = relu(u[4])\n",
    "    u[5] = F.conv2d(m[4], net.W6, net.b6, stride=2, padding=1); sig[5] = relu(u[5])\n",
    "    \n",
    "    # Block 4\n",
    "    u[6] = F.conv2d(m[5], net.W7, net.b7, stride=1, padding=1); sig[6] = relu(u[6])\n",
    "    u[7] = F.conv2d(m[6], net.W8, net.b8, stride=2, padding=1); sig[7] = relu(u[7])\n",
    "    \n",
    "    # FC\n",
    "    B = x0.shape[0]\n",
    "    m8_flat = m[7].reshape(B, -1)\n",
    "    u[8] = m8_flat @ net.W9.t() + net.b9\n",
    "    sig[8] = u[8] \n",
    "\n",
    "    return u, sig\n",
    "\n",
    "class XZState:\n",
    "    def __init__(self, B, device):\n",
    "        self.dims = [\n",
    "            (B, 64, 32, 32), (B, 64, 16, 16),\n",
    "            (B, 128, 16, 16), (B, 128, 8, 8),\n",
    "            (B, 256, 8, 8),   (B, 256, 4, 4),\n",
    "            (B, 512, 4, 4),   (B, 512, 2, 2),\n",
    "            (B, 10)\n",
    "        ]\n",
    "        self.x = [torch.zeros(d, device=device) for d in self.dims]\n",
    "        self.z = [torch.zeros(d, device=device) for d in self.dims]\n",
    "\n",
    "    def reset(self, B, device):\n",
    "        if self.x[0].shape[0] != B:\n",
    "            self.__init__(B, device)\n",
    "\n",
    "# -----------------------------\n",
    "# Hamiltonian x-z relaxation gradient for batch (CNN9)\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def xz_relax_batch_grad(\n",
    "    net: CNN9, x0, y,\n",
    "    eta=1.0, K=25,\n",
    "    state: XZState | None = None,\n",
    "    tol: float = 1e-4,\n",
    "    warm_start: bool = True,\n",
    "    beta: float = 1.0,\n",
    "):\n",
    "    device = net.device\n",
    "    B = x0.shape[0]\n",
    "    num_layers = 9\n",
    "    \n",
    "    # --- CHANGE 1: Label Smoothing (Preserves Fidelity, improves Acc) ---\n",
    "    eps_ls = 0.1\n",
    "    y_onehot = F.one_hot(y, num_classes=10).to(x0.dtype)\n",
    "    y_smooth = (1.0 - eps_ls) * y_onehot + eps_ls / 10.0\n",
    "\n",
    "    # Initialize State\n",
    "    if state is None:\n",
    "        state = XZState(B, device)\n",
    "    else:\n",
    "        state.reset(B, device)\n",
    "    \n",
    "    x = state.x; z = state.z\n",
    "    \n",
    "    steps_taken = 0\n",
    "    for _ in range(K):\n",
    "        steps_taken += 1\n",
    "        \n",
    "        m = [(xi + zi) * 0.5 for xi, zi in zip(x, z)]\n",
    "        s = [(xi - zi) for xi, zi in zip(x, z)]\n",
    "        \n",
    "        u, sig = forward_u_sig(net, x0, m)\n",
    "\n",
    "        F_err = [(si - mi) for si, mi in zip(sig, m)]\n",
    "        \n",
    "        p = torch.softmax(m[8], dim=1)\n",
    "        \n",
    "        # Use smoothed labels for gradient\n",
    "        g_last = (p - y_smooth)\n",
    "        \n",
    "        q = [None] * num_layers\n",
    "        q[8] = s[8] \n",
    "        for i in range(7, -1, -1):\n",
    "            q[i] = relu_prime(u[i]) * s[i]\n",
    "\n",
    "        Jt = [None] * num_layers\n",
    "        Jt[8] = -s[8] \n",
    "\n",
    "        # Jt for Layer 8\n",
    "        WTq8 = (q[8] @ net.W9).reshape(B, 512, 2, 2)\n",
    "        Jt[7] = -s[7] + WTq8\n",
    "        \n",
    "        # Jt for Conv Layers\n",
    "        Jt[6] = -s[6] + F.conv_transpose2d(q[7], net.W8, stride=2, padding=1, output_padding=1)\n",
    "        Jt[5] = -s[5] + F.conv_transpose2d(q[6], net.W7, stride=1, padding=1)\n",
    "        Jt[4] = -s[4] + F.conv_transpose2d(q[5], net.W6, stride=2, padding=1, output_padding=1)\n",
    "        Jt[3] = -s[3] + F.conv_transpose2d(q[4], net.W5, stride=1, padding=1)\n",
    "        Jt[2] = -s[2] + F.conv_transpose2d(q[3], net.W4, stride=2, padding=1, output_padding=1)\n",
    "        Jt[1] = -s[1] + F.conv_transpose2d(q[2], net.W3, stride=1, padding=1)\n",
    "        Jt[0] = -s[0] + F.conv_transpose2d(q[1], net.W2, stride=2, padding=1, output_padding=1)\n",
    "\n",
    "        total_change = 0.0\n",
    "        # Layers 0 to 7\n",
    "        for i in range(8):\n",
    "            dx = F_err[i] + 0.5 * Jt[i]\n",
    "            dz = F_err[i] - 0.5 * Jt[i]\n",
    "            x[i].add_(dx, alpha=eta)\n",
    "            z[i].add_(dz, alpha=eta)\n",
    "            total_change += dx.abs().mean().item()\n",
    "            \n",
    "        # Layer 8 (Output)\n",
    "        dx8 = F_err[8] + 0.5 * Jt[8] + 0.5 * beta * g_last\n",
    "        dz8 = F_err[8] - 0.5 * Jt[8] - 0.5 * beta * g_last\n",
    "        x[8].add_(dx8, alpha=eta)\n",
    "        z[8].add_(dz8, alpha=eta)\n",
    "        total_change += dx8.abs().mean().item()\n",
    "\n",
    "        if total_change < tol:\n",
    "            break\n",
    "\n",
    "    # Compute Gradients\n",
    "    m = [(xi + zi) * 0.5 for xi, zi in zip(x, z)]\n",
    "    s = [(xi - zi) for xi, zi in zip(x, z)]\n",
    "    u, _ = forward_u_sig(net, x0, m)\n",
    "    \n",
    "    delta = [None] * num_layers\n",
    "    delta[8] = s[8]\n",
    "    for i in range(8):\n",
    "        delta[i] = relu_prime(u[i]) * s[i]\n",
    "\n",
    "    gradsW = []\n",
    "    gradsb = []\n",
    "\n",
    "    # W1 (stride 1)\n",
    "    gradsW.append(conv2d_weight(x0, net.W1.shape, delta[0], stride=1, padding=1) / B)\n",
    "    gradsb.append(delta[0].sum(dim=(0,2,3)) / B)\n",
    "    # W2 (stride 2)\n",
    "    gradsW.append(conv2d_weight(m[0], net.W2.shape, delta[1], stride=2, padding=1) / B)\n",
    "    gradsb.append(delta[1].sum(dim=(0,2,3)) / B)\n",
    "    # W3 (stride 1)\n",
    "    gradsW.append(conv2d_weight(m[1], net.W3.shape, delta[2], stride=1, padding=1) / B)\n",
    "    gradsb.append(delta[2].sum(dim=(0,2,3)) / B)\n",
    "    # W4 (stride 2)\n",
    "    gradsW.append(conv2d_weight(m[2], net.W4.shape, delta[3], stride=2, padding=1) / B)\n",
    "    gradsb.append(delta[3].sum(dim=(0,2,3)) / B)\n",
    "    # W5 (stride 1)\n",
    "    gradsW.append(conv2d_weight(m[3], net.W5.shape, delta[4], stride=1, padding=1) / B)\n",
    "    gradsb.append(delta[4].sum(dim=(0,2,3)) / B)\n",
    "    # W6 (stride 2)\n",
    "    gradsW.append(conv2d_weight(m[4], net.W6.shape, delta[5], stride=2, padding=1) / B)\n",
    "    gradsb.append(delta[5].sum(dim=(0,2,3)) / B)\n",
    "    # W7 (stride 1)\n",
    "    gradsW.append(conv2d_weight(m[5], net.W7.shape, delta[6], stride=1, padding=1) / B)\n",
    "    gradsb.append(delta[6].sum(dim=(0,2,3)) / B)\n",
    "    # W8 (stride 2)\n",
    "    gradsW.append(conv2d_weight(m[6], net.W8.shape, delta[7], stride=2, padding=1) / B)\n",
    "    gradsb.append(delta[7].sum(dim=(0,2,3)) / B)\n",
    "    # W9 (Linear)\n",
    "    m7_flat = m[7].reshape(B, -1)\n",
    "    gradsW.append((delta[8].t() @ m7_flat) / B)\n",
    "    gradsb.append(delta[8].mean(dim=0))\n",
    "\n",
    "    ce = F.cross_entropy(m[8], y).item()\n",
    "    return tuple(gradsW), tuple(gradsb), ce, steps_taken\n",
    "\n",
    "# -----------------------------\n",
    "# Autograd Reference (Standard CNN9, No BN to match Relaxation)\n",
    "# -----------------------------\n",
    "# -----------------------------\n",
    "# Autograd Reference (Now matches Label Smoothing)\n",
    "# -----------------------------\n",
    "def autograd_grads_like_cnn9(net: CNN9, x, y):\n",
    "    params = {}\n",
    "    for i in range(1, 10):\n",
    "        params[f\"W{i}\"] = getattr(net, f\"W{i}\").detach().clone().requires_grad_(True)\n",
    "        params[f\"b{i}\"] = getattr(net, f\"b{i}\").detach().clone().requires_grad_(True)\n",
    "    \n",
    "    h = x\n",
    "    h = relu(F.conv2d(h, params['W1'], params['b1'], stride=1, padding=1))\n",
    "    h = relu(F.conv2d(h, params['W2'], params['b2'], stride=2, padding=1))\n",
    "    h = relu(F.conv2d(h, params['W3'], params['b3'], stride=1, padding=1))\n",
    "    h = relu(F.conv2d(h, params['W4'], params['b4'], stride=2, padding=1))\n",
    "    h = relu(F.conv2d(h, params['W5'], params['b5'], stride=1, padding=1))\n",
    "    h = relu(F.conv2d(h, params['W6'], params['b6'], stride=2, padding=1))\n",
    "    h = relu(F.conv2d(h, params['W7'], params['b7'], stride=1, padding=1))\n",
    "    h = relu(F.conv2d(h, params['W8'], params['b8'], stride=2, padding=1))\n",
    "    logits = h.reshape(x.size(0), -1) @ params['W9'].t() + params['b9']\n",
    "    \n",
    "    # --- FIX: Match the relaxation's label smoothing (eps=0.1) ---\n",
    "    loss = F.cross_entropy(logits, y, label_smoothing=0.1)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    gradsW = tuple(params[f\"W{i}\"].grad for i in range(1, 10))\n",
    "    gradsb = tuple(params[f\"b{i}\"].grad for i in range(1, 10))\n",
    "    return gradsW, gradsb, float(loss.detach())\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics & Plotting\n",
    "# -----------------------------\n",
    "def flat_cat(tup):\n",
    "    return torch.cat([t.reshape(-1) for t in tup], dim=0)\n",
    "\n",
    "def cos_sim(a, b, eps=1e-12):\n",
    "    denom = (a.norm() * b.norm()).clamp_min(eps)\n",
    "    return float((a @ b) / denom)\n",
    "\n",
    "def relative_error(a, b, eps=1e-12):\n",
    "    return float((a - b).norm() / b.norm().clamp_min(eps))\n",
    "\n",
    "def set_style():\n",
    "    mpl.rcParams.update({\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.serif\": [\"Times New Roman\", \"DejaVu Serif\"],\n",
    "        \"font.size\": 14,\n",
    "        \"axes.labelsize\": 16,\n",
    "        \"axes.titlesize\": 18,\n",
    "        \"lines.linewidth\": 2.5,\n",
    "        \"figure.figsize\": (8, 6),\n",
    "    })\n",
    "\n",
    "def plot_results_icml(results, eta_values):\n",
    "    set_style()\n",
    "    plt.figure()\n",
    "    styles = {\n",
    "        0.8: {'color': '#d62728', 'marker': 'o', 'linestyle': '-'},\n",
    "        1.0: {'color': '#1f77b4', 'marker': 's', 'linestyle': '--'},\n",
    "        1.2: {'color': '#2ca02c', 'marker': '^', 'linestyle': '-.'},\n",
    "    }\n",
    "    for eta in eta_values:\n",
    "        if eta not in results: continue\n",
    "        data = results[eta]\n",
    "        cos_steps = data['cos_steps']\n",
    "        rel_err = data['relerr_globalW_hist']\n",
    "        if len(cos_steps) == 0: continue\n",
    "        style = styles.get(eta, {'color': 'black', 'marker': 'x', 'linestyle': ':'})\n",
    "        plt.plot(cos_steps, rel_err, label=fr'$\\eta={eta}$', **style)\n",
    "\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Training Steps')\n",
    "    plt.ylabel(r'Relative Grad Error')\n",
    "    plt.title('Gradient Fidelity (CNN9)')\n",
    "    plt.grid(True, which=\"both\", ls=\":\", alpha=0.6)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('cnn9_grad_fidelity.png', dpi=300)\n",
    "    print(\"Saved cnn9_grad_fidelity.png\")\n",
    "\n",
    "def plot_convergence_icml(results, eta_values):\n",
    "    set_style()\n",
    "    plt.figure()\n",
    "    styles = {\n",
    "        0.8: {'color': '#d62728', 'marker': 'o', 'linestyle': '-'},\n",
    "        1.0: {'color': '#1f77b4', 'marker': 's', 'linestyle': '--'},\n",
    "        1.2: {'color': '#2ca02c', 'marker': '^', 'linestyle': '-.'},\n",
    "    }\n",
    "    for eta in eta_values:\n",
    "        if eta not in results: continue\n",
    "        data = results[eta]\n",
    "        avg_steps = data['avg_steps_per_epoch']\n",
    "        epochs = range(1, len(avg_steps) + 1)\n",
    "        style = styles.get(eta, {'color': 'black', 'marker': 'x', 'linestyle': ':'})\n",
    "        plt.plot(epochs, avg_steps, label=fr'$\\eta={eta}$', **style)\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Avg. Convergence Steps ($K$)')\n",
    "    plt.title('Relaxation Convergence Speed (CNN9)')\n",
    "    plt.grid(True, which=\"both\", ls=\":\", alpha=0.6)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('cnn9_convergence_steps.png', dpi=300)\n",
    "    print(\"Saved cnn9_convergence_steps.png\")\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def sgd_momentum_step(net: CNN9, gradsW, gradsb, vW, vb,\n",
    "                      lr=0.01, momentum=0.9, weight_decay=5e-4, clip=1.0):\n",
    "    for i in range(9):\n",
    "        dWi = gradsW[i] + weight_decay * getattr(net, f\"W{i+1}\")\n",
    "        dbi = gradsb[i]\n",
    "        \n",
    "        gn = (dWi.norm()**2 + dbi.norm()**2)**0.5\n",
    "        scale = 1.0 if gn <= clip else (clip / (gn + 1e-12))\n",
    "        dWi *= scale; dbi *= scale\n",
    "\n",
    "        vW[i].mul_(momentum).add_(dWi)\n",
    "        vb[i].mul_(momentum).add_(dbi)\n",
    "\n",
    "        getattr(net, f\"W{i+1}\").sub_(lr * vW[i])\n",
    "        getattr(net, f\"b{i+1}\").sub_(lr * vb[i])\n",
    "\n",
    "@torch.no_grad()\n",
    "def ema_update(ema_net: CNN9, net: CNN9, decay=0.999):\n",
    "    for i in range(1, 10):\n",
    "        for param in [\"W\", \"b\"]:\n",
    "            name = f\"{param}{i}\"\n",
    "            getattr(ema_net, name).mul_(decay).add_(getattr(net, name), alpha=(1.0 - decay))\n",
    "\n",
    "@torch.no_grad()\n",
    "def accuracy(net: CNN9, loader, device, max_batches=800):\n",
    "    correct = 0; total = 0\n",
    "    for i, (x,y) in enumerate(loader):\n",
    "        if i >= max_batches: break\n",
    "        x = x.to(device); y = y.to(device)\n",
    "        h = x\n",
    "        h = relu(F.conv2d(h, net.W1, net.b1, stride=1, padding=1))\n",
    "        h = relu(F.conv2d(h, net.W2, net.b2, stride=2, padding=1))\n",
    "        h = relu(F.conv2d(h, net.W3, net.b3, stride=1, padding=1))\n",
    "        h = relu(F.conv2d(h, net.W4, net.b4, stride=2, padding=1))\n",
    "        h = relu(F.conv2d(h, net.W5, net.b5, stride=1, padding=1))\n",
    "        h = relu(F.conv2d(h, net.W6, net.b6, stride=2, padding=1))\n",
    "        h = relu(F.conv2d(h, net.W7, net.b7, stride=1, padding=1))\n",
    "        h = relu(F.conv2d(h, net.W8, net.b8, stride=2, padding=1))\n",
    "        logits = h.reshape(x.size(0), -1) @ net.W9.t() + net.b9\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.numel()\n",
    "    return correct / max(1, total)\n",
    "\n",
    "def kaiming_init(shape, device):\n",
    "    fan_in = (shape[1] * shape[2] * shape[3]) if len(shape) == 4 else shape[1]\n",
    "    return math.sqrt(2.0 / fan_in) * torch.randn(shape, device=device)\n",
    "\n",
    "def cosine_lr(step, total_steps, lr_max=0.05, lr_min=5e-4):\n",
    "    t = step / max(1, total_steps)\n",
    "    return lr_min + 0.5*(lr_max - lr_min)*(1.0 + math.cos(math.pi * t))\n",
    "\n",
    "# -----------------------------\n",
    "# Data Augmentation (Cutout - KEEPING THIS)\n",
    "# -----------------------------\n",
    "class Cutout(object):\n",
    "    def __init__(self, length):\n",
    "        self.length = length\n",
    "\n",
    "    def __call__(self, img):\n",
    "        _, h, w = img.shape\n",
    "        mask = torch.ones((h, w), dtype=torch.float32)\n",
    "        y = torch.randint(h, (1,)).item()\n",
    "        x = torch.randint(w, (1,)).item()\n",
    "        y1 = max(0, y - self.length // 2)\n",
    "        y2 = min(h, y + self.length // 2)\n",
    "        x1 = max(0, x - self.length // 2)\n",
    "        x2 = min(w, x + self.length // 2)\n",
    "        img[:, y1:y2, x1:x2] = 0.0\n",
    "        return img\n",
    "\n",
    "# -----------------------------\n",
    "# Main\n",
    "# -----------------------------\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    cifar_mean = (0.4914, 0.4822, 0.4465)\n",
    "    cifar_std  = (0.2470, 0.2435, 0.2616)\n",
    "    \n",
    "    # --- CHANGE 2: Cutout (Safe for gradient fidelity) ---\n",
    "    train_tfm = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(cifar_mean, cifar_std),\n",
    "        Cutout(length=8)\n",
    "    ])\n",
    "    test_tfm = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(cifar_mean, cifar_std)\n",
    "    ])\n",
    "    \n",
    "    train_ds = datasets.CIFAR10(\"./data\", train=True, download=True, transform=train_tfm)\n",
    "    test_ds  = datasets.CIFAR10(\"./data\", train=False, download=True, transform=test_tfm)\n",
    "    train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    test_loader  = DataLoader(test_ds, batch_size=256, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    epochs = 100\n",
    "    K = 30\n",
    "    lr_max = 0.033 # Back to slightly safer LR without BN\n",
    "    lr_min = 0.0002\n",
    "    eta_values = [1.0] \n",
    "    compare_every = 100\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    for eta in eta_values:\n",
    "        print(f\"\\nTraining CNN9 (eta={eta})...\")\n",
    "        \n",
    "        W1 = kaiming_init((64, 3, 3, 3), device);   b1 = torch.zeros(64, device=device)\n",
    "        W2 = kaiming_init((64, 64, 3, 3), device);  b2 = torch.zeros(64, device=device)\n",
    "        W3 = kaiming_init((128, 64, 3, 3), device);  b3 = torch.zeros(128, device=device)\n",
    "        W4 = kaiming_init((128, 128, 3, 3), device); b4 = torch.zeros(128, device=device)\n",
    "        W5 = kaiming_init((256, 128, 3, 3), device); b5 = torch.zeros(256, device=device)\n",
    "        W6 = kaiming_init((256, 256, 3, 3), device); b6 = torch.zeros(256, device=device)\n",
    "        W7 = kaiming_init((512, 256, 3, 3), device); b7 = torch.zeros(512, device=device)\n",
    "        W8 = kaiming_init((512, 512, 3, 3), device); b8 = torch.zeros(512, device=device)\n",
    "        W9 = kaiming_init((10, 512*2*2), device);    b9 = torch.zeros(10, device=device)\n",
    "\n",
    "        net = CNN9(W1,b1,W2,b2,W3,b3,W4,b4,W5,b5,W6,b6,W7,b7,W8,b8,W9,b9)\n",
    "        ema_net = CNN9(W1.clone(),b1.clone(),W2.clone(),b2.clone(),W3.clone(),b3.clone(),\n",
    "                       W4.clone(),b4.clone(),W5.clone(),b5.clone(),W6.clone(),b6.clone(),\n",
    "                       W7.clone(),b7.clone(),W8.clone(),b8.clone(),W9.clone(),b9.clone())\n",
    "\n",
    "        vW = [torch.zeros_like(getattr(net, f\"W{i}\")) for i in range(1,10)]\n",
    "        vb = [torch.zeros_like(getattr(net, f\"b{i}\")) for i in range(1,10)]\n",
    "\n",
    "        total_steps = epochs * len(train_loader)\n",
    "        global_step = 0\n",
    "        state = None \n",
    "        \n",
    "        cos_globalW_hist = []\n",
    "        relerr_globalW_hist = []\n",
    "        cos_steps = []\n",
    "        avg_steps_per_epoch = []\n",
    "\n",
    "        for ep in range(1, epochs+1):\n",
    "            running_ce = 0.0\n",
    "            epoch_steps_accum = 0\n",
    "            num_batches = 0\n",
    "            \n",
    "            for i, (x, y) in enumerate(train_loader):\n",
    "                x = x.to(device, non_blocking=True)\n",
    "                y = y.to(device, non_blocking=True)\n",
    "                lr = cosine_lr(global_step, total_steps, lr_max=lr_max, lr_min=lr_min)\n",
    "\n",
    "                gradsW, gradsb, ce, steps_taken = xz_relax_batch_grad(\n",
    "                    net, x, y, eta=eta, K=K, state=state, warm_start=True\n",
    "                )\n",
    "                if state is None: state = XZState(x.shape[0], device)\n",
    "\n",
    "                # Fidelity Check\n",
    "                if global_step % compare_every == 0:\n",
    "                    gradsW_ag, _, _ = autograd_grads_like_cnn9(net, x, y)\n",
    "                    gx = flat_cat(gradsW)\n",
    "                    ga = flat_cat(gradsW_ag)\n",
    "                    c_sim = cos_sim(gx, ga)\n",
    "                    r_err = relative_error(gx, ga)\n",
    "                    cos_globalW_hist.append(c_sim)\n",
    "                    relerr_globalW_hist.append(r_err)\n",
    "                    cos_steps.append(global_step)\n",
    "                    print(f\"[Step {global_step}] CosSim: {c_sim:.4f} | RelErr: {r_err:.4f}\")\n",
    "\n",
    "                sgd_momentum_step(net, gradsW, gradsb, vW, vb, lr=lr)\n",
    "                \n",
    "                # --- CHANGE 3: EMA decay higher ---\n",
    "                ema_update(ema_net, net, decay=0.9995)\n",
    "\n",
    "                global_step += 1\n",
    "                running_ce += ce\n",
    "                epoch_steps_accum += steps_taken\n",
    "                num_batches += 1\n",
    "\n",
    "            test_acc = accuracy(ema_net, test_loader, device)\n",
    "            train_loss = running_ce / num_batches\n",
    "            avg_k = epoch_steps_accum / num_batches\n",
    "            avg_steps_per_epoch.append(avg_k)\n",
    "            print(f\">>> Ep {ep}: Loss {train_loss:.4f} | ACC {test_acc*100:.2f}% | Avg K: {avg_k:.1f}\")\n",
    "\n",
    "        results[eta] = {\n",
    "            'cos_globalW_hist': cos_globalW_hist,\n",
    "            'relerr_globalW_hist': relerr_globalW_hist,\n",
    "            'cos_steps': cos_steps,\n",
    "            'avg_steps_per_epoch': avg_steps_per_epoch\n",
    "        }\n",
    "\n",
    "    print(\"Generating Plots...\")\n",
    "    plot_results_icml(results, eta_values)\n",
    "    plot_convergence_icml(results, eta_values)\n",
    "    \n",
    "    final_acc = accuracy(ema_net, test_loader, device, max_batches=2000)\n",
    "    print(f\"\\nFinal Test Accuracy: {final_acc*100:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3bad11",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4285fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "========================================\n",
      "Training CNN9 (eta=0.25, K=1000, tol=1e-06)\n",
      "========================================\n",
      "[Step 0] CosSim: 1.0000 | RelErr: 0.0003\n",
      "[Step 500] CosSim: 1.0000 | RelErr: 0.0003\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 64, 3, 3], expected input[256, 3, 32, 32] to have 64 channels, but got 3 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 546\u001b[39m\n\u001b[32m    543\u001b[39m     plot_convergence_icml(results, eta_values)\n\u001b[32m    545\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m546\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 523\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    520\u001b[39m     epoch_steps_accum += steps_taken\n\u001b[32m    521\u001b[39m     num_batches += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m test_acc = \u001b[43maccuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mema_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    524\u001b[39m train_loss = running_ce / num_batches\n\u001b[32m    525\u001b[39m avg_k = epoch_steps_accum / num_batches\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 365\u001b[39m, in \u001b[36maccuracy\u001b[39m\u001b[34m(net, loader, device, max_batches)\u001b[39m\n\u001b[32m    363\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i >= max_batches: \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    364\u001b[39m x = x.to(device); y = y.to(device)\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m u, _ = \u001b[43mforward_u_sig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Dummy m for forward structure, actual func handles it\u001b[39;00m\n\u001b[32m    366\u001b[39m \u001b[38;5;66;03m# Actually need simple forward here to match standard inference\u001b[39;00m\n\u001b[32m    367\u001b[39m h = x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mforward_u_sig\u001b[39m\u001b[34m(net, x0, m)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Block 1\u001b[39;00m\n\u001b[32m     56\u001b[39m u[\u001b[32m0\u001b[39m] = F.conv2d(x0, net.W1, net.b1, stride=\u001b[32m1\u001b[39m, padding=\u001b[32m1\u001b[39m);   sig[\u001b[32m0\u001b[39m] = relu(u[\u001b[32m0\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m u[\u001b[32m1\u001b[39m] = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mW2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mb2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m; sig[\u001b[32m1\u001b[39m] = relu(u[\u001b[32m1\u001b[39m])\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# Block 2\u001b[39;00m\n\u001b[32m     60\u001b[39m u[\u001b[32m2\u001b[39m] = F.conv2d(m[\u001b[32m1\u001b[39m], net.W3, net.b3, stride=\u001b[32m1\u001b[39m, padding=\u001b[32m1\u001b[39m); sig[\u001b[32m2\u001b[39m] = relu(u[\u001b[32m2\u001b[39m])\n",
      "\u001b[31mRuntimeError\u001b[39m: Given groups=1, weight of size [64, 64, 3, 3], expected input[256, 3, 32, 32] to have 64 channels, but got 3 channels instead"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from dataclasses import dataclass\n",
    "from torch.nn.grad import conv2d_weight\n",
    "import os\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "# -----------------------------\n",
    "# Activations\n",
    "# -----------------------------\n",
    "def relu(u): return torch.relu(u)\n",
    "def relu_prime(u): return (u > 0).to(u.dtype)\n",
    "\n",
    "# -----------------------------\n",
    "# Model container (CNN9)\n",
    "# -----------------------------\n",
    "@dataclass\n",
    "class CNN9:\n",
    "    # Block 1: 32x32 -> 16x16\n",
    "    W1: torch.Tensor; b1: torch.Tensor   # (64, 3, 3, 3)   s=1\n",
    "    W2: torch.Tensor; b2: torch.Tensor   # (64, 64, 3, 3)  s=2 (pool)\n",
    "    \n",
    "    # Block 2: 16x16 -> 8x8\n",
    "    W3: torch.Tensor; b3: torch.Tensor   # (128, 64, 3, 3) s=1\n",
    "    W4: torch.Tensor; b4: torch.Tensor   # (128, 128, 3, 3) s=2 (pool)\n",
    "    \n",
    "    # Block 3: 8x8 -> 4x4\n",
    "    W5: torch.Tensor; b5: torch.Tensor   # (256, 128, 3, 3) s=1\n",
    "    W6: torch.Tensor; b6: torch.Tensor   # (256, 256, 3, 3) s=2 (pool)\n",
    "    \n",
    "    # Block 4: 4x4 -> 2x2\n",
    "    W7: torch.Tensor; b7: torch.Tensor   # (512, 256, 3, 3) s=1\n",
    "    W8: torch.Tensor; b8: torch.Tensor   # (512, 512, 3, 3) s=2 (pool)\n",
    "    \n",
    "    # Classifier: 2x2 -> Flat\n",
    "    W9: torch.Tensor; b9: torch.Tensor   # (10, 512*2*2)\n",
    "\n",
    "    @property\n",
    "    def device(self): return self.W1.device\n",
    "\n",
    "# -----------------------------\n",
    "# Forward at mean states\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def forward_u_sig(net: CNN9, x0, m):\n",
    "    u = [None] * 9\n",
    "    sig = [None] * 9\n",
    "    \n",
    "    # Block 1\n",
    "    u[0] = F.conv2d(x0, net.W1, net.b1, stride=1, padding=1);   sig[0] = relu(u[0])\n",
    "    u[1] = F.conv2d(m[0], net.W2, net.b2, stride=2, padding=1); sig[1] = relu(u[1])\n",
    "    \n",
    "    # Block 2\n",
    "    u[2] = F.conv2d(m[1], net.W3, net.b3, stride=1, padding=1); sig[2] = relu(u[2])\n",
    "    u[3] = F.conv2d(m[2], net.W4, net.b4, stride=2, padding=1); sig[3] = relu(u[3])\n",
    "    \n",
    "    # Block 3\n",
    "    u[4] = F.conv2d(m[3], net.W5, net.b5, stride=1, padding=1); sig[4] = relu(u[4])\n",
    "    u[5] = F.conv2d(m[4], net.W6, net.b6, stride=2, padding=1); sig[5] = relu(u[5])\n",
    "    \n",
    "    # Block 4\n",
    "    u[6] = F.conv2d(m[5], net.W7, net.b7, stride=1, padding=1); sig[6] = relu(u[6])\n",
    "    u[7] = F.conv2d(m[6], net.W8, net.b8, stride=2, padding=1); sig[7] = relu(u[7])\n",
    "    \n",
    "    # FC\n",
    "    B = x0.shape[0]\n",
    "    m8_flat = m[7].reshape(B, -1)\n",
    "    u[8] = m8_flat @ net.W9.t() + net.b9\n",
    "    sig[8] = u[8] \n",
    "\n",
    "    return u, sig\n",
    "\n",
    "class XZState:\n",
    "    def __init__(self, B, device):\n",
    "        self.dims = [\n",
    "            (B, 64, 32, 32), (B, 64, 16, 16),\n",
    "            (B, 128, 16, 16), (B, 128, 8, 8),\n",
    "            (B, 256, 8, 8),   (B, 256, 4, 4),\n",
    "            (B, 512, 4, 4),   (B, 512, 2, 2),\n",
    "            (B, 10)\n",
    "        ]\n",
    "        self.x = [torch.zeros(d, device=device) for d in self.dims]\n",
    "        self.z = [torch.zeros(d, device=device) for d in self.dims]\n",
    "\n",
    "    def reset(self, B, device):\n",
    "        if self.x[0].shape[0] != B:\n",
    "            self.__init__(B, device)\n",
    "\n",
    "# -----------------------------\n",
    "# Relaxation Gradient\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def xz_relax_batch_grad(\n",
    "    net: CNN9, x0, y,\n",
    "    eta=1.0, K=25,\n",
    "    state: XZState | None = None,\n",
    "    tol: float = 1e-4,\n",
    "    warm_start: bool = True,\n",
    "    beta: float = 1.0,\n",
    "):\n",
    "    device = net.device\n",
    "    B = x0.shape[0]\n",
    "    num_layers = 9\n",
    "    \n",
    "    # Label Smoothing\n",
    "    eps_ls = 0.1\n",
    "    y_onehot = F.one_hot(y, num_classes=10).to(x0.dtype)\n",
    "    y_smooth = (1.0 - eps_ls) * y_onehot + eps_ls / 10.0\n",
    "\n",
    "    if state is None:\n",
    "        state = XZState(B, device)\n",
    "    else:\n",
    "        state.reset(B, device)\n",
    "    \n",
    "    x = state.x; z = state.z\n",
    "    \n",
    "    steps_taken = 0\n",
    "    for _ in range(K):\n",
    "        steps_taken += 1\n",
    "        \n",
    "        m = [(xi + zi) * 0.5 for xi, zi in zip(x, z)]\n",
    "        s = [(xi - zi) for xi, zi in zip(x, z)]\n",
    "        \n",
    "        u, sig = forward_u_sig(net, x0, m)\n",
    "        F_err = [(si - mi) for si, mi in zip(sig, m)]\n",
    "        \n",
    "        p = torch.softmax(m[8], dim=1)\n",
    "        g_last = (p - y_smooth)\n",
    "        \n",
    "        q = [None] * num_layers\n",
    "        q[8] = s[8] \n",
    "        for i in range(7, -1, -1):\n",
    "            q[i] = relu_prime(u[i]) * s[i]\n",
    "\n",
    "        Jt = [None] * num_layers\n",
    "        Jt[8] = -s[8] \n",
    "        WTq8 = (q[8] @ net.W9).reshape(B, 512, 2, 2)\n",
    "        Jt[7] = -s[7] + WTq8\n",
    "        Jt[6] = -s[6] + F.conv_transpose2d(q[7], net.W8, stride=2, padding=1, output_padding=1)\n",
    "        Jt[5] = -s[5] + F.conv_transpose2d(q[6], net.W7, stride=1, padding=1)\n",
    "        Jt[4] = -s[4] + F.conv_transpose2d(q[5], net.W6, stride=2, padding=1, output_padding=1)\n",
    "        Jt[3] = -s[3] + F.conv_transpose2d(q[4], net.W5, stride=1, padding=1)\n",
    "        Jt[2] = -s[2] + F.conv_transpose2d(q[3], net.W4, stride=2, padding=1, output_padding=1)\n",
    "        Jt[1] = -s[1] + F.conv_transpose2d(q[2], net.W3, stride=1, padding=1)\n",
    "        Jt[0] = -s[0] + F.conv_transpose2d(q[1], net.W2, stride=2, padding=1, output_padding=1)\n",
    "\n",
    "        total_change = 0.0\n",
    "        # Hidden Layers\n",
    "        for i in range(8):\n",
    "            dx = F_err[i] + 0.5 * Jt[i]\n",
    "            dz = F_err[i] - 0.5 * Jt[i]\n",
    "            x[i].add_(dx, alpha=eta)\n",
    "            z[i].add_(dz, alpha=eta)\n",
    "            total_change += dx.abs().mean().item()\n",
    "            \n",
    "        # Output Layer\n",
    "        dx8 = F_err[8] + 0.5 * Jt[8] + 0.5 * beta * g_last\n",
    "        dz8 = F_err[8] - 0.5 * Jt[8] - 0.5 * beta * g_last\n",
    "        x[8].add_(dx8, alpha=eta)\n",
    "        z[8].add_(dz8, alpha=eta)\n",
    "        total_change += dx8.abs().mean().item()\n",
    "\n",
    "        if total_change < tol:\n",
    "            break\n",
    "\n",
    "    # Compute Gradients\n",
    "    m = [(xi + zi) * 0.5 for xi, zi in zip(x, z)]\n",
    "    s = [(xi - zi) for xi, zi in zip(x, z)]\n",
    "    u, _ = forward_u_sig(net, x0, m)\n",
    "    \n",
    "    delta = [None] * num_layers\n",
    "    delta[8] = s[8]\n",
    "    for i in range(8):\n",
    "        delta[i] = relu_prime(u[i]) * s[i]\n",
    "\n",
    "    gradsW = []\n",
    "    gradsb = []\n",
    "\n",
    "    # Manual conv gradients to match architecture\n",
    "    gradsW.append(conv2d_weight(x0, net.W1.shape, delta[0], stride=1, padding=1) / B)\n",
    "    gradsb.append(delta[0].sum(dim=(0,2,3)) / B)\n",
    "    \n",
    "    gradsW.append(conv2d_weight(m[0], net.W2.shape, delta[1], stride=2, padding=1) / B)\n",
    "    gradsb.append(delta[1].sum(dim=(0,2,3)) / B)\n",
    "    \n",
    "    gradsW.append(conv2d_weight(m[1], net.W3.shape, delta[2], stride=1, padding=1) / B)\n",
    "    gradsb.append(delta[2].sum(dim=(0,2,3)) / B)\n",
    "    \n",
    "    gradsW.append(conv2d_weight(m[2], net.W4.shape, delta[3], stride=2, padding=1) / B)\n",
    "    gradsb.append(delta[3].sum(dim=(0,2,3)) / B)\n",
    "    \n",
    "    gradsW.append(conv2d_weight(m[3], net.W5.shape, delta[4], stride=1, padding=1) / B)\n",
    "    gradsb.append(delta[4].sum(dim=(0,2,3)) / B)\n",
    "    \n",
    "    gradsW.append(conv2d_weight(m[4], net.W6.shape, delta[5], stride=2, padding=1) / B)\n",
    "    gradsb.append(delta[5].sum(dim=(0,2,3)) / B)\n",
    "    \n",
    "    gradsW.append(conv2d_weight(m[5], net.W7.shape, delta[6], stride=1, padding=1) / B)\n",
    "    gradsb.append(delta[6].sum(dim=(0,2,3)) / B)\n",
    "    \n",
    "    gradsW.append(conv2d_weight(m[6], net.W8.shape, delta[7], stride=2, padding=1) / B)\n",
    "    gradsb.append(delta[7].sum(dim=(0,2,3)) / B)\n",
    "    \n",
    "    m7_flat = m[7].reshape(B, -1)\n",
    "    gradsW.append((delta[8].t() @ m7_flat) / B)\n",
    "    gradsb.append(delta[8].mean(dim=0))\n",
    "\n",
    "    ce = F.cross_entropy(m[8], y).item()\n",
    "    return tuple(gradsW), tuple(gradsb), ce, steps_taken\n",
    "\n",
    "# -----------------------------\n",
    "# Autograd Reference\n",
    "# -----------------------------\n",
    "def autograd_grads_like_cnn9(net: CNN9, x, y):\n",
    "    params = {}\n",
    "    for i in range(1, 10):\n",
    "        params[f\"W{i}\"] = getattr(net, f\"W{i}\").detach().clone().requires_grad_(True)\n",
    "        params[f\"b{i}\"] = getattr(net, f\"b{i}\").detach().clone().requires_grad_(True)\n",
    "    \n",
    "    h = x\n",
    "    h = relu(F.conv2d(h, params['W1'], params['b1'], stride=1, padding=1))\n",
    "    h = relu(F.conv2d(h, params['W2'], params['b2'], stride=2, padding=1))\n",
    "    h = relu(F.conv2d(h, params['W3'], params['b3'], stride=1, padding=1))\n",
    "    h = relu(F.conv2d(h, params['W4'], params['b4'], stride=2, padding=1))\n",
    "    h = relu(F.conv2d(h, params['W5'], params['b5'], stride=1, padding=1))\n",
    "    h = relu(F.conv2d(h, params['W6'], params['b6'], stride=2, padding=1))\n",
    "    h = relu(F.conv2d(h, params['W7'], params['b7'], stride=1, padding=1))\n",
    "    h = relu(F.conv2d(h, params['W8'], params['b8'], stride=2, padding=1))\n",
    "    logits = h.reshape(x.size(0), -1) @ params['W9'].t() + params['b9']\n",
    "    \n",
    "    loss = F.cross_entropy(logits, y, label_smoothing=0.1)\n",
    "    loss.backward()\n",
    "    \n",
    "    gradsW = tuple(params[f\"W{i}\"].grad for i in range(1, 10))\n",
    "    gradsb = tuple(params[f\"b{i}\"].grad for i in range(1, 10))\n",
    "    return gradsW, gradsb, float(loss.detach())\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics & Plotting\n",
    "# -----------------------------\n",
    "def flat_cat(tup):\n",
    "    return torch.cat([t.reshape(-1) for t in tup], dim=0)\n",
    "\n",
    "def cos_sim(a, b, eps=1e-12):\n",
    "    denom = (a.norm() * b.norm()).clamp_min(eps)\n",
    "    return float((a @ b) / denom)\n",
    "\n",
    "def relative_error(a, b, eps=1e-12):\n",
    "    return float((a - b).norm() / b.norm().clamp_min(eps))\n",
    "\n",
    "def set_style():\n",
    "    mpl.rcParams.update({\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.serif\": [\"Times New Roman\", \"DejaVu Serif\"],\n",
    "        \"font.size\": 14,\n",
    "        \"axes.labelsize\": 16,\n",
    "        \"axes.titlesize\": 18,\n",
    "        \"lines.linewidth\": 2.5,\n",
    "        \"figure.figsize\": (8, 6),\n",
    "    })\n",
    "\n",
    "def plot_results_icml(results, eta_values):\n",
    "    set_style()\n",
    "    plt.figure()\n",
    "    \n",
    "    # Define distinct styles for the 4 requested etas\n",
    "    styles = {\n",
    "        0.25: {'color': '#1f77b4', 'marker': 'o', 'linestyle': '-', 'label': r'$\\eta=0.25$'},  # Blue\n",
    "        0.50: {'color': '#ff7f0e', 'marker': 's', 'linestyle': '--', 'label': r'$\\eta=0.50$'},  # Orange\n",
    "        0.75: {'color': '#2ca02c', 'marker': '^', 'linestyle': '-.', 'label': r'$\\eta=0.75$'},  # Green\n",
    "        1.00: {'color': '#d62728', 'marker': 'D', 'linestyle': ':', 'label': r'$\\eta=1.00$'},  # Red\n",
    "    }\n",
    "    \n",
    "    for eta in eta_values:\n",
    "        if eta not in results: continue\n",
    "        data = results[eta]\n",
    "        cos_steps = data['cos_steps']\n",
    "        rel_err = data['relerr_globalW_hist']\n",
    "        if len(cos_steps) == 0: continue\n",
    "        \n",
    "        # Get style or default\n",
    "        st = styles.get(eta, {'color': 'black', 'marker': 'x', 'linestyle': '-'})\n",
    "        \n",
    "        plt.plot(cos_steps, rel_err, **st)\n",
    "\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Training Steps')\n",
    "    plt.ylabel(r'Relative Grad Error')\n",
    "    plt.title('Gradient Fidelity (CNN9)')\n",
    "    plt.grid(True, which=\"both\", ls=\":\", alpha=0.6)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('cnn9_grad_fidelity.png', dpi=300)\n",
    "    print(\"Saved cnn9_grad_fidelity.png\")\n",
    "\n",
    "def plot_convergence_icml(results, eta_values):\n",
    "    set_style()\n",
    "    plt.figure()\n",
    "    \n",
    "    styles = {\n",
    "        0.25: {'color': '#1f77b4', 'marker': 'o', 'linestyle': '-', 'label': r'$\\eta=0.25$'},\n",
    "        0.50: {'color': '#ff7f0e', 'marker': 's', 'linestyle': '--', 'label': r'$\\eta=0.50$'},\n",
    "        0.75: {'color': '#2ca02c', 'marker': '^', 'linestyle': '-.', 'label': r'$\\eta=0.75$'},\n",
    "        1.00: {'color': '#d62728', 'marker': 'D', 'linestyle': ':', 'label': r'$\\eta=1.00$'},\n",
    "    }\n",
    "    \n",
    "    for eta in eta_values:\n",
    "        if eta not in results: continue\n",
    "        data = results[eta]\n",
    "        avg_steps = data['avg_steps_per_epoch']\n",
    "        epochs = range(1, len(avg_steps) + 1)\n",
    "        \n",
    "        st = styles.get(eta, {'color': 'black', 'marker': 'x', 'linestyle': '-'})\n",
    "        \n",
    "        plt.plot(epochs, avg_steps, **st)\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Avg. Convergence Steps ($K$)')\n",
    "    plt.title('Relaxation Convergence Speed (CNN9)')\n",
    "    plt.grid(True, which=\"both\", ls=\":\", alpha=0.6)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('cnn9_convergence_steps.png', dpi=300)\n",
    "    print(\"Saved cnn9_convergence_steps.png\")\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def sgd_momentum_step(net: CNN9, gradsW, gradsb, vW, vb,\n",
    "                      lr=0.01, momentum=0.9, weight_decay=5e-4, clip=1.0):\n",
    "    for i in range(9):\n",
    "        dWi = gradsW[i] + weight_decay * getattr(net, f\"W{i+1}\")\n",
    "        dbi = gradsb[i]\n",
    "        \n",
    "        gn = (dWi.norm()**2 + dbi.norm()**2)**0.5\n",
    "        scale = 1.0 if gn <= clip else (clip / (gn + 1e-12))\n",
    "        dWi *= scale; dbi *= scale\n",
    "\n",
    "        vW[i].mul_(momentum).add_(dWi)\n",
    "        vb[i].mul_(momentum).add_(dbi)\n",
    "\n",
    "        getattr(net, f\"W{i+1}\").sub_(lr * vW[i])\n",
    "        getattr(net, f\"b{i+1}\").sub_(lr * vb[i])\n",
    "\n",
    "@torch.no_grad()\n",
    "def ema_update(ema_net: CNN9, net: CNN9, decay=0.999):\n",
    "    for i in range(1, 10):\n",
    "        for param in [\"W\", \"b\"]:\n",
    "            name = f\"{param}{i}\"\n",
    "            getattr(ema_net, name).mul_(decay).add_(getattr(net, name), alpha=(1.0 - decay))\n",
    "\n",
    "@torch.no_grad()\n",
    "def accuracy(net: CNN9, loader, device, max_batches=800):\n",
    "    correct = 0; total = 0\n",
    "    for i, (x,y) in enumerate(loader):\n",
    "        if i >= max_batches: break\n",
    "        x = x.to(device); y = y.to(device)\n",
    "        u, _ = forward_u_sig(net, x, [torch.zeros_like(x)] * 8) # Dummy m for forward structure, actual func handles it\n",
    "        # Actually need simple forward here to match standard inference\n",
    "        h = x\n",
    "        h = relu(F.conv2d(h, net.W1, net.b1, stride=1, padding=1))\n",
    "        h = relu(F.conv2d(h, net.W2, net.b2, stride=2, padding=1))\n",
    "        h = relu(F.conv2d(h, net.W3, net.b3, stride=1, padding=1))\n",
    "        h = relu(F.conv2d(h, net.W4, net.b4, stride=2, padding=1))\n",
    "        h = relu(F.conv2d(h, net.W5, net.b5, stride=1, padding=1))\n",
    "        h = relu(F.conv2d(h, net.W6, net.b6, stride=2, padding=1))\n",
    "        h = relu(F.conv2d(h, net.W7, net.b7, stride=1, padding=1))\n",
    "        h = relu(F.conv2d(h, net.W8, net.b8, stride=2, padding=1))\n",
    "        logits = h.reshape(x.size(0), -1) @ net.W9.t() + net.b9\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.numel()\n",
    "    return correct / max(1, total)\n",
    "\n",
    "def kaiming_init(shape, device):\n",
    "    fan_in = (shape[1] * shape[2] * shape[3]) if len(shape) == 4 else shape[1]\n",
    "    return math.sqrt(2.0 / fan_in) * torch.randn(shape, device=device)\n",
    "\n",
    "def cosine_lr(step, total_steps, lr_max=0.05, lr_min=5e-4):\n",
    "    t = step / max(1, total_steps)\n",
    "    return lr_min + 0.5*(lr_max - lr_min)*(1.0 + math.cos(math.pi * t))\n",
    "\n",
    "class Cutout(object):\n",
    "    def __init__(self, length):\n",
    "        self.length = length\n",
    "    def __call__(self, img):\n",
    "        _, h, w = img.shape\n",
    "        mask = torch.ones((h, w), dtype=torch.float32)\n",
    "        y = torch.randint(h, (1,)).item()\n",
    "        x = torch.randint(w, (1,)).item()\n",
    "        y1 = max(0, y - self.length // 2)\n",
    "        y2 = min(h, y + self.length // 2)\n",
    "        x1 = max(0, x - self.length // 2)\n",
    "        x2 = min(w, x + self.length // 2)\n",
    "        img[:, y1:y2, x1:x2] = 0.0\n",
    "        return img\n",
    "\n",
    "# -----------------------------\n",
    "# Main\n",
    "# -----------------------------\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    cifar_mean = (0.4914, 0.4822, 0.4465)\n",
    "    cifar_std  = (0.2470, 0.2435, 0.2616)\n",
    "    \n",
    "    train_tfm = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(cifar_mean, cifar_std),\n",
    "        Cutout(length=8)\n",
    "    ])\n",
    "    test_tfm = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(cifar_mean, cifar_std)\n",
    "    ])\n",
    "    \n",
    "    train_ds = datasets.CIFAR10(\"./data\", train=True, download=True, transform=train_tfm)\n",
    "    test_ds  = datasets.CIFAR10(\"./data\", train=False, download=True, transform=test_tfm)\n",
    "    train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    test_loader  = DataLoader(test_ds, batch_size=256, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    epochs = 100\n",
    "    \n",
    "    # --- UPDATED PARAMETERS ---\n",
    "    # Iterating over the requested 4 etas\n",
    "    eta_values = [0.25, 0.5, 0.75, 1.0]\n",
    "    \n",
    "    # Increased K to 1000\n",
    "    K_limit = 1000 \n",
    "    \n",
    "    # Higher tolerance of 1e-6\n",
    "    tolerance = 1e-6\n",
    "    \n",
    "    lr_max = 0.035\n",
    "    lr_min = 0.0002\n",
    "    compare_every = 100\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    for eta in eta_values:\n",
    "        print(f\"\\n========================================\")\n",
    "        print(f\"Training CNN9 (eta={eta}, K={K_limit}, tol={tolerance})\")\n",
    "        print(f\"========================================\")\n",
    "        \n",
    "        # Init Model\n",
    "        W1 = kaiming_init((64, 3, 3, 3), device);   b1 = torch.zeros(64, device=device)\n",
    "        W2 = kaiming_init((64, 64, 3, 3), device);  b2 = torch.zeros(64, device=device)\n",
    "        W3 = kaiming_init((128, 64, 3, 3), device);  b3 = torch.zeros(128, device=device)\n",
    "        W4 = kaiming_init((128, 128, 3, 3), device); b4 = torch.zeros(128, device=device)\n",
    "        W5 = kaiming_init((256, 128, 3, 3), device); b5 = torch.zeros(256, device=device)\n",
    "        W6 = kaiming_init((256, 256, 3, 3), device); b6 = torch.zeros(256, device=device)\n",
    "        W7 = kaiming_init((512, 256, 3, 3), device); b7 = torch.zeros(512, device=device)\n",
    "        W8 = kaiming_init((512, 512, 3, 3), device); b8 = torch.zeros(512, device=device)\n",
    "        W9 = kaiming_init((10, 512*2*2), device);    b9 = torch.zeros(10, device=device)\n",
    "\n",
    "        net = CNN9(W1,b1,W2,b2,W3,b3,W4,b4,W5,b5,W6,b6,W7,b7,W8,b8,W9,b9)\n",
    "        ema_net = CNN9(W1.clone(),b1.clone(),W2.clone(),b2.clone(),W3.clone(),b3.clone(),\n",
    "                       W4.clone(),b4.clone(),W5.clone(),b5.clone(),W6.clone(),b6.clone(),\n",
    "                       W7.clone(),b7.clone(),W8.clone(),b8.clone(),W9.clone(),b9.clone())\n",
    "\n",
    "        vW = [torch.zeros_like(getattr(net, f\"W{i}\")) for i in range(1,10)]\n",
    "        vb = [torch.zeros_like(getattr(net, f\"b{i}\")) for i in range(1,10)]\n",
    "\n",
    "        total_steps = epochs * len(train_loader)\n",
    "        global_step = 0\n",
    "        state = None \n",
    "        \n",
    "        cos_globalW_hist = []\n",
    "        relerr_globalW_hist = []\n",
    "        cos_steps = []\n",
    "        avg_steps_per_epoch = []\n",
    "\n",
    "        for ep in range(1, epochs+1):\n",
    "            running_ce = 0.0\n",
    "            epoch_steps_accum = 0\n",
    "            num_batches = 0\n",
    "            \n",
    "            for i, (x, y) in enumerate(train_loader):\n",
    "                x = x.to(device, non_blocking=True)\n",
    "                y = y.to(device, non_blocking=True)\n",
    "                lr = cosine_lr(global_step, total_steps, lr_max=lr_max, lr_min=lr_min)\n",
    "\n",
    "                # Passing updated K and Tol here\n",
    "                gradsW, gradsb, ce, steps_taken = xz_relax_batch_grad(\n",
    "                    net, x, y, eta=eta, K=K_limit, state=state, tol=tolerance, warm_start=True\n",
    "                )\n",
    "                if state is None: state = XZState(x.shape[0], device)\n",
    "\n",
    "                # Fidelity Check\n",
    "                if global_step % compare_every == 0:\n",
    "                    gradsW_ag, _, _ = autograd_grads_like_cnn9(net, x, y)\n",
    "                    gx = flat_cat(gradsW)\n",
    "                    ga = flat_cat(gradsW_ag)\n",
    "                    c_sim = cos_sim(gx, ga)\n",
    "                    r_err = relative_error(gx, ga)\n",
    "                    cos_globalW_hist.append(c_sim)\n",
    "                    relerr_globalW_hist.append(r_err)\n",
    "                    cos_steps.append(global_step)\n",
    "                    \n",
    "                    # Optional: Print progress less frequently to reduce clutter\n",
    "                    if global_step % (compare_every * 5) == 0:\n",
    "                        print(f\"[Step {global_step}] CosSim: {c_sim:.4f} | RelErr: {r_err:.4f}\")\n",
    "\n",
    "                sgd_momentum_step(net, gradsW, gradsb, vW, vb, lr=lr)\n",
    "                ema_update(ema_net, net, decay=0.9995)\n",
    "\n",
    "                global_step += 1\n",
    "                running_ce += ce\n",
    "                epoch_steps_accum += steps_taken\n",
    "                num_batches += 1\n",
    "\n",
    "            test_acc = accuracy(ema_net, test_loader, device)\n",
    "            train_loss = running_ce / num_batches\n",
    "            avg_k = epoch_steps_accum / num_batches\n",
    "            avg_steps_per_epoch.append(avg_k)\n",
    "            print(f\">>> Ep {ep}: Loss {train_loss:.4f} | ACC {test_acc*100:.2f}% | Avg K: {avg_k:.1f}\")\n",
    "\n",
    "        results[eta] = {\n",
    "            'cos_globalW_hist': cos_globalW_hist,\n",
    "            'relerr_globalW_hist': relerr_globalW_hist,\n",
    "            'cos_steps': cos_steps,\n",
    "            'avg_steps_per_epoch': avg_steps_per_epoch\n",
    "        }\n",
    "\n",
    "    # --- SAVE DATA FOR POST PROCESSING ---\n",
    "    print(\"\\nSaving results to experiment_data.pt ...\")\n",
    "    torch.save(results, \"experiment_data.pt\")\n",
    "    print(\"Data Saved.\")\n",
    "\n",
    "    print(\"Generating Plots...\")\n",
    "    plot_results_icml(results, eta_values)\n",
    "    plot_convergence_icml(results, eta_values)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e35555f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "========================================\n",
      "Training CNN9 (eta=0.25, K=1000, tol=1e-06)\n",
      "========================================\n",
      "[Step 0] Global Cos: 1.0000 | Global RelErr: 0.0013 | NormRatio: 1.0000 | W9 RelErr: 0.0000 | Last K: 999\n",
      "[Step 100] Global Cos: 1.0000 | Global RelErr: 0.0007 | NormRatio: 1.0000 | W9 RelErr: 0.0000 | Last K: 156\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 582\u001b[39m\n\u001b[32m    579\u001b[39m     plot_convergence_icml(results, eta_values)\n\u001b[32m    581\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m582\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 493\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    490\u001b[39m y = y.to(device, non_blocking=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    491\u001b[39m lr = cosine_lr(global_step, total_steps, lr_max=lr_max, lr_min=lr_min)\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m gradsW, gradsb, ce, steps_taken = \u001b[43mxz_relax_batch_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[43m=\u001b[49m\u001b[43meta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m=\u001b[49m\u001b[43mK_limit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurrent_tol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\n\u001b[32m    495\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[38;5;66;03m# ---- LOGGING BLOCK EVERY 100 STEPS ----\u001b[39;00m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_step % compare_every == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 143\u001b[39m, in \u001b[36mxz_relax_batch_grad\u001b[39m\u001b[34m(net, x0, y, eta, K, state, tol, warm_start, beta)\u001b[39m\n\u001b[32m    141\u001b[39m Jt = [\u001b[38;5;28;01mNone\u001b[39;00m] * num_layers\n\u001b[32m    142\u001b[39m Jt[\u001b[32m8\u001b[39m] = -s[\u001b[32m8\u001b[39m] \n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m WTq8 = \u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mW9\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m Jt[\u001b[32m7\u001b[39m] = -s[\u001b[32m7\u001b[39m] + WTq8\n\u001b[32m    145\u001b[39m Jt[\u001b[32m6\u001b[39m] = -s[\u001b[32m6\u001b[39m] + F.conv_transpose2d(q[\u001b[32m7\u001b[39m], net.W8, stride=\u001b[32m2\u001b[39m, padding=\u001b[32m1\u001b[39m, output_padding=\u001b[32m1\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from dataclasses import dataclass\n",
    "from torch.nn.grad import conv2d_weight\n",
    "import os\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "# -----------------------------\n",
    "# Activations\n",
    "# -----------------------------\n",
    "def relu(u): return torch.relu(u)\n",
    "def relu_prime(u): return (u > 0).to(u.dtype)\n",
    "\n",
    "# -----------------------------\n",
    "# Model container (CNN9)\n",
    "# -----------------------------\n",
    "@dataclass\n",
    "class CNN9:\n",
    "    # Block 1: 32x32 -> 16x16\n",
    "    W1: torch.Tensor; b1: torch.Tensor   # (64, 3, 3, 3)   s=1\n",
    "    W2: torch.Tensor; b2: torch.Tensor   # (64, 64, 3, 3)  s=2 (pool)\n",
    "    \n",
    "    # Block 2: 16x16 -> 8x8\n",
    "    W3: torch.Tensor; b3: torch.Tensor   # (128, 64, 3, 3) s=1\n",
    "    W4: torch.Tensor; b4: torch.Tensor   # (128, 128, 3, 3) s=2 (pool)\n",
    "    \n",
    "    # Block 3: 8x8 -> 4x4\n",
    "    W5: torch.Tensor; b5: torch.Tensor   # (256, 128, 3, 3) s=1\n",
    "    W6: torch.Tensor; b6: torch.Tensor   # (256, 256, 3, 3) s=2 (pool)\n",
    "    \n",
    "    # Block 4: 4x4 -> 2x2\n",
    "    W7: torch.Tensor; b7: torch.Tensor   # (512, 256, 3, 3) s=1\n",
    "    W8: torch.Tensor; b8: torch.Tensor   # (512, 512, 3, 3) s=2 (pool)\n",
    "    \n",
    "    # Classifier: 2x2 -> Flat\n",
    "    W9: torch.Tensor; b9: torch.Tensor   # (10, 512*2*2)\n",
    "\n",
    "    @property\n",
    "    def device(self): return self.W1.device\n",
    "\n",
    "# -----------------------------\n",
    "# Forward at mean states\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def forward_u_sig(net: CNN9, x0, m):\n",
    "    u = [None] * 9\n",
    "    sig = [None] * 9\n",
    "    \n",
    "    # Block 1\n",
    "    u[0] = F.conv2d(x0, net.W1, net.b1, stride=1, padding=1);   sig[0] = relu(u[0])\n",
    "    u[1] = F.conv2d(m[0], net.W2, net.b2, stride=2, padding=1); sig[1] = relu(u[1])\n",
    "    \n",
    "    # Block 2\n",
    "    u[2] = F.conv2d(m[1], net.W3, net.b3, stride=1, padding=1); sig[2] = relu(u[2])\n",
    "    u[3] = F.conv2d(m[2], net.W4, net.b4, stride=2, padding=1); sig[3] = relu(u[3])\n",
    "    \n",
    "    # Block 3\n",
    "    u[4] = F.conv2d(m[3], net.W5, net.b5, stride=1, padding=1); sig[4] = relu(u[4])\n",
    "    u[5] = F.conv2d(m[4], net.W6, net.b6, stride=2, padding=1); sig[5] = relu(u[5])\n",
    "    \n",
    "    # Block 4\n",
    "    u[6] = F.conv2d(m[5], net.W7, net.b7, stride=1, padding=1); sig[6] = relu(u[6])\n",
    "    u[7] = F.conv2d(m[6], net.W8, net.b8, stride=2, padding=1); sig[7] = relu(u[7])\n",
    "    \n",
    "    # FC\n",
    "    B = x0.shape[0]\n",
    "    m8_flat = m[7].reshape(B, -1)\n",
    "    u[8] = m8_flat @ net.W9.t() + net.b9\n",
    "    sig[8] = u[8] \n",
    "\n",
    "    return u, sig\n",
    "\n",
    "class XZState:\n",
    "    def __init__(self, B, device):\n",
    "        self.dims = [\n",
    "            (B, 64, 32, 32), (B, 64, 16, 16),\n",
    "            (B, 128, 16, 16), (B, 128, 8, 8),\n",
    "            (B, 256, 8, 8),   (B, 256, 4, 4),\n",
    "            (B, 512, 4, 4),   (B, 512, 2, 2),\n",
    "            (B, 10)\n",
    "        ]\n",
    "        self.x = [torch.zeros(d, device=device) for d in self.dims]\n",
    "        self.z = [torch.zeros(d, device=device) for d in self.dims]\n",
    "\n",
    "    def reset(self, B, device):\n",
    "        if self.x[0].shape[0] != B:\n",
    "            self.__init__(B, device)\n",
    "\n",
    "# -----------------------------\n",
    "# Relaxation Gradient\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def xz_relax_batch_grad(\n",
    "    net: CNN9, x0, y,\n",
    "    eta=1.0, K=25,\n",
    "    state: XZState | None = None,\n",
    "    tol: float = 1e-4,\n",
    "    warm_start: bool = True,\n",
    "    beta: float = 1.0,\n",
    "):\n",
    "    device = net.device\n",
    "    B = x0.shape[0]\n",
    "    num_layers = 9\n",
    "    \n",
    "    # Label Smoothing\n",
    "    eps_ls = 0.1\n",
    "    y_onehot = F.one_hot(y, num_classes=10).to(x0.dtype)\n",
    "    y_smooth = (1.0 - eps_ls) * y_onehot + eps_ls / 10.0\n",
    "\n",
    "    if state is None:\n",
    "        state = XZState(B, device)\n",
    "    else:\n",
    "        state.reset(B, device)\n",
    "    \n",
    "    x = state.x; z = state.z\n",
    "    \n",
    "    steps_taken = 0\n",
    "    for _ in range(K):\n",
    "        steps_taken += 1\n",
    "        \n",
    "        m = [(xi + zi) * 0.5 for xi, zi in zip(x, z)]\n",
    "        s = [(xi - zi) for xi, zi in zip(x, z)]\n",
    "        \n",
    "        u, sig = forward_u_sig(net, x0, m)\n",
    "        F_err = [(si - mi) for si, mi in zip(sig, m)]\n",
    "        \n",
    "        p = torch.softmax(m[8], dim=1)\n",
    "        g_last = (p - y_smooth)\n",
    "        \n",
    "        q = [None] * num_layers\n",
    "        q[8] = s[8] \n",
    "        for i in range(7, -1, -1):\n",
    "            q[i] = relu_prime(u[i]) * s[i]\n",
    "\n",
    "        Jt = [None] * num_layers\n",
    "        Jt[8] = -s[8] \n",
    "        WTq8 = (q[8] @ net.W9).reshape(B, 512, 2, 2)\n",
    "        Jt[7] = -s[7] + WTq8\n",
    "        Jt[6] = -s[6] + F.conv_transpose2d(q[7], net.W8, stride=2, padding=1, output_padding=1)\n",
    "        Jt[5] = -s[5] + F.conv_transpose2d(q[6], net.W7, stride=1, padding=1)\n",
    "        Jt[4] = -s[4] + F.conv_transpose2d(q[5], net.W6, stride=2, padding=1, output_padding=1)\n",
    "        Jt[3] = -s[3] + F.conv_transpose2d(q[4], net.W5, stride=1, padding=1)\n",
    "        Jt[2] = -s[2] + F.conv_transpose2d(q[3], net.W4, stride=2, padding=1, output_padding=1)\n",
    "        Jt[1] = -s[1] + F.conv_transpose2d(q[2], net.W3, stride=1, padding=1)\n",
    "        Jt[0] = -s[0] + F.conv_transpose2d(q[1], net.W2, stride=2, padding=1, output_padding=1)\n",
    "\n",
    "        total_change = 0.0\n",
    "        # Hidden Layers\n",
    "        for i in range(8):\n",
    "            dx = F_err[i] + 0.5 * Jt[i]\n",
    "            dz = F_err[i] - 0.5 * Jt[i]\n",
    "            x[i].add_(dx, alpha=eta)\n",
    "            z[i].add_(dz, alpha=eta)\n",
    "            total_change += dx.abs().mean().item()\n",
    "            \n",
    "        # Output Layer\n",
    "        dx8 = F_err[8] + 0.5 * Jt[8] + 0.5 * beta * g_last\n",
    "        dz8 = F_err[8] - 0.5 * Jt[8] - 0.5 * beta * g_last\n",
    "        x[8].add_(dx8, alpha=eta)\n",
    "        z[8].add_(dz8, alpha=eta)\n",
    "        total_change += dx8.abs().mean().item()\n",
    "\n",
    "        if total_change < tol:\n",
    "            break\n",
    "\n",
    "    # Compute Gradients\n",
    "    m = [(xi + zi) * 0.5 for xi, zi in zip(x, z)]\n",
    "    s = [(xi - zi) for xi, zi in zip(x, z)]\n",
    "    u, _ = forward_u_sig(net, x0, m)\n",
    "    \n",
    "    delta = [None] * num_layers\n",
    "    delta[8] = s[8]\n",
    "    for i in range(8):\n",
    "        delta[i] = relu_prime(u[i]) * s[i]\n",
    "\n",
    "    gradsW = []\n",
    "    gradsb = []\n",
    "\n",
    "    # Manual conv gradients to match architecture\n",
    "    gradsW.append(conv2d_weight(x0, net.W1.shape, delta[0], stride=1, padding=1) / B)\n",
    "    gradsb.append(delta[0].sum(dim=(0,2,3)) / B)\n",
    "    \n",
    "    gradsW.append(conv2d_weight(m[0], net.W2.shape, delta[1], stride=2, padding=1) / B)\n",
    "    gradsb.append(delta[1].sum(dim=(0,2,3)) / B)\n",
    "    \n",
    "    gradsW.append(conv2d_weight(m[1], net.W3.shape, delta[2], stride=1, padding=1) / B)\n",
    "    gradsb.append(delta[2].sum(dim=(0,2,3)) / B)\n",
    "    \n",
    "    gradsW.append(conv2d_weight(m[2], net.W4.shape, delta[3], stride=2, padding=1) / B)\n",
    "    gradsb.append(delta[3].sum(dim=(0,2,3)) / B)\n",
    "    \n",
    "    gradsW.append(conv2d_weight(m[3], net.W5.shape, delta[4], stride=1, padding=1) / B)\n",
    "    gradsb.append(delta[4].sum(dim=(0,2,3)) / B)\n",
    "    \n",
    "    gradsW.append(conv2d_weight(m[4], net.W6.shape, delta[5], stride=2, padding=1) / B)\n",
    "    gradsb.append(delta[5].sum(dim=(0,2,3)) / B)\n",
    "    \n",
    "    gradsW.append(conv2d_weight(m[5], net.W7.shape, delta[6], stride=1, padding=1) / B)\n",
    "    gradsb.append(delta[6].sum(dim=(0,2,3)) / B)\n",
    "    \n",
    "    gradsW.append(conv2d_weight(m[6], net.W8.shape, delta[7], stride=2, padding=1) / B)\n",
    "    gradsb.append(delta[7].sum(dim=(0,2,3)) / B)\n",
    "    \n",
    "    m7_flat = m[7].reshape(B, -1)\n",
    "    gradsW.append((delta[8].t() @ m7_flat) / B)\n",
    "    gradsb.append(delta[8].mean(dim=0))\n",
    "\n",
    "    ce = F.cross_entropy(m[8], y).item()\n",
    "    return tuple(gradsW), tuple(gradsb), ce, steps_taken -1\n",
    "\n",
    "# -----------------------------\n",
    "# Autograd Reference\n",
    "# -----------------------------\n",
    "def autograd_grads_like_cnn9(net: CNN9, x, y):\n",
    "    params = {}\n",
    "    for i in range(1, 10):\n",
    "        params[f\"W{i}\"] = getattr(net, f\"W{i}\").detach().clone().requires_grad_(True)\n",
    "        params[f\"b{i}\"] = getattr(net, f\"b{i}\").detach().clone().requires_grad_(True)\n",
    "    \n",
    "    h = x\n",
    "    h = relu(F.conv2d(h, params['W1'], params['b1'], stride=1, padding=1))\n",
    "    h = relu(F.conv2d(h, params['W2'], params['b2'], stride=2, padding=1))\n",
    "    h = relu(F.conv2d(h, params['W3'], params['b3'], stride=1, padding=1))\n",
    "    h = relu(F.conv2d(h, params['W4'], params['b4'], stride=2, padding=1))\n",
    "    h = relu(F.conv2d(h, params['W5'], params['b5'], stride=1, padding=1))\n",
    "    h = relu(F.conv2d(h, params['W6'], params['b6'], stride=2, padding=1))\n",
    "    h = relu(F.conv2d(h, params['W7'], params['b7'], stride=1, padding=1))\n",
    "    h = relu(F.conv2d(h, params['W8'], params['b8'], stride=2, padding=1))\n",
    "    logits = h.reshape(x.size(0), -1) @ params['W9'].t() + params['b9']\n",
    "    \n",
    "    loss = F.cross_entropy(logits, y, label_smoothing=0.1)\n",
    "    loss.backward()\n",
    "    \n",
    "    gradsW = tuple(params[f\"W{i}\"].grad for i in range(1, 10))\n",
    "    gradsb = tuple(params[f\"b{i}\"].grad for i in range(1, 10))\n",
    "    return gradsW, gradsb, float(loss.detach())\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics & Plotting\n",
    "# -----------------------------\n",
    "def flat_cat(tup):\n",
    "    return torch.cat([t.reshape(-1) for t in tup], dim=0)\n",
    "\n",
    "def cos_sim(a, b, eps=1e-12):\n",
    "    # Fix: Flatten tensors to 1D vectors before dot product\n",
    "    a_flat = a.flatten()\n",
    "    b_flat = b.flatten()\n",
    "    denom = (a_flat.norm() * b_flat.norm()).clamp_min(eps)\n",
    "    return float((a_flat @ b_flat) / denom)\n",
    "\n",
    "def relative_error(a, b, eps=1e-12):\n",
    "    return float((a - b).norm() / b.norm().clamp_min(eps))\n",
    "\n",
    "def set_style():\n",
    "    mpl.rcParams.update({\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.serif\": [\"Times New Roman\", \"DejaVu Serif\"],\n",
    "        \"font.size\": 14,\n",
    "        \"axes.labelsize\": 16,\n",
    "        \"axes.titlesize\": 18,\n",
    "        \"lines.linewidth\": 2.5,\n",
    "        \"figure.figsize\": (8, 6),\n",
    "    })\n",
    "\n",
    "def plot_results_icml(results, eta_values):\n",
    "    set_style()\n",
    "    plt.figure()\n",
    "    \n",
    "    styles = {\n",
    "        0.25: {'color': '#1f77b4', 'marker': 'o', 'linestyle': '-', 'label': r'$\\eta=0.25$'},\n",
    "        0.50: {'color': '#ff7f0e', 'marker': 's', 'linestyle': '--', 'label': r'$\\eta=0.50$'},\n",
    "        0.75: {'color': '#2ca02c', 'marker': '^', 'linestyle': '-.', 'label': r'$\\eta=0.75$'},\n",
    "        1.00: {'color': '#d62728', 'marker': 'D', 'linestyle': ':', 'label': r'$\\eta=1.00$'},\n",
    "    }\n",
    "    \n",
    "    for eta in eta_values:\n",
    "        if eta not in results: continue\n",
    "        data = results[eta]\n",
    "        cos_steps = data['cos_steps']\n",
    "        rel_err = data['relerr_globalW_hist']\n",
    "        if len(cos_steps) == 0: continue\n",
    "        \n",
    "        st = styles.get(eta, {'color': 'black', 'marker': 'x', 'linestyle': '-'})\n",
    "        plt.plot(cos_steps, rel_err, **st)\n",
    "\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Training Steps')\n",
    "    plt.ylabel(r'Relative Grad Error')\n",
    "    plt.title('Global Gradient Fidelity (CNN9)')\n",
    "    plt.grid(True, which=\"both\", ls=\":\", alpha=0.6)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('cnn9_grad_fidelity.png', dpi=300)\n",
    "    print(\"Saved cnn9_grad_fidelity.png\")\n",
    "\n",
    "def plot_convergence_icml(results, eta_values):\n",
    "    set_style()\n",
    "    plt.figure()\n",
    "    \n",
    "    styles = {\n",
    "        0.25: {'color': '#1f77b4', 'marker': 'o', 'linestyle': '-', 'label': r'$\\eta=0.25$'},\n",
    "        0.50: {'color': '#ff7f0e', 'marker': 's', 'linestyle': '--', 'label': r'$\\eta=0.50$'},\n",
    "        0.75: {'color': '#2ca02c', 'marker': '^', 'linestyle': '-.', 'label': r'$\\eta=0.75$'},\n",
    "        1.00: {'color': '#d62728', 'marker': 'D', 'linestyle': ':', 'label': r'$\\eta=1.00$'},\n",
    "    }\n",
    "    \n",
    "    for eta in eta_values:\n",
    "        if eta not in results: continue\n",
    "        data = results[eta]\n",
    "        avg_steps = data['avg_steps_per_epoch']\n",
    "        epochs = range(1, len(avg_steps) + 1)\n",
    "        \n",
    "        st = styles.get(eta, {'color': 'black', 'marker': 'x', 'linestyle': '-'})\n",
    "        plt.plot(epochs, avg_steps, **st)\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Avg. Convergence Steps ($K$)')\n",
    "    plt.title('Relaxation Convergence Speed (CNN9)')\n",
    "    plt.grid(True, which=\"both\", ls=\":\", alpha=0.6)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('cnn9_convergence_steps.png', dpi=300)\n",
    "    print(\"Saved cnn9_convergence_steps.png\")\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def sgd_momentum_step(net: CNN9, gradsW, gradsb, vW, vb,\n",
    "                      lr=0.01, momentum=0.9, weight_decay=5e-4, clip=1.0):\n",
    "    for i in range(9):\n",
    "        dWi = gradsW[i] + weight_decay * getattr(net, f\"W{i+1}\")\n",
    "        dbi = gradsb[i]\n",
    "        \n",
    "        gn = (dWi.norm()**2 + dbi.norm()**2)**0.5\n",
    "        scale = 1.0 if gn <= clip else (clip / (gn + 1e-12))\n",
    "        dWi *= scale; dbi *= scale\n",
    "\n",
    "        vW[i].mul_(momentum).add_(dWi)\n",
    "        vb[i].mul_(momentum).add_(dbi)\n",
    "\n",
    "        getattr(net, f\"W{i+1}\").sub_(lr * vW[i])\n",
    "        getattr(net, f\"b{i+1}\").sub_(lr * vb[i])\n",
    "\n",
    "@torch.no_grad()\n",
    "def ema_update(ema_net: CNN9, net: CNN9, decay=0.999):\n",
    "    for i in range(1, 10):\n",
    "        for param in [\"W\", \"b\"]:\n",
    "            name = f\"{param}{i}\"\n",
    "            getattr(ema_net, name).mul_(decay).add_(getattr(net, name), alpha=(1.0 - decay))\n",
    "\n",
    "@torch.no_grad()\n",
    "def accuracy(net: CNN9, loader, device, max_batches=800):\n",
    "    correct = 0; total = 0\n",
    "    for i, (x,y) in enumerate(loader):\n",
    "        if i >= max_batches: break\n",
    "        x = x.to(device); y = y.to(device)\n",
    "        \n",
    "        h = x\n",
    "        h = relu(F.conv2d(h, net.W1, net.b1, stride=1, padding=1))\n",
    "        h = relu(F.conv2d(h, net.W2, net.b2, stride=2, padding=1))\n",
    "        h = relu(F.conv2d(h, net.W3, net.b3, stride=1, padding=1))\n",
    "        h = relu(F.conv2d(h, net.W4, net.b4, stride=2, padding=1))\n",
    "        h = relu(F.conv2d(h, net.W5, net.b5, stride=1, padding=1))\n",
    "        h = relu(F.conv2d(h, net.W6, net.b6, stride=2, padding=1))\n",
    "        h = relu(F.conv2d(h, net.W7, net.b7, stride=1, padding=1))\n",
    "        h = relu(F.conv2d(h, net.W8, net.b8, stride=2, padding=1))\n",
    "        logits = h.reshape(x.size(0), -1) @ net.W9.t() + net.b9\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.numel()\n",
    "    return correct / max(1, total)\n",
    "\n",
    "def kaiming_init(shape, device):\n",
    "    fan_in = (shape[1] * shape[2] * shape[3]) if len(shape) == 4 else shape[1]\n",
    "    return math.sqrt(2.0 / fan_in) * torch.randn(shape, device=device)\n",
    "\n",
    "def cosine_lr(step, total_steps, lr_max=0.05, lr_min=5e-4):\n",
    "    t = step / max(1, total_steps)\n",
    "    return lr_min + 0.5*(lr_max - lr_min)*(1.0 + math.cos(math.pi * t))\n",
    "\n",
    "class Cutout(object):\n",
    "    def __init__(self, length):\n",
    "        self.length = length\n",
    "    def __call__(self, img):\n",
    "        _, h, w = img.shape\n",
    "        mask = torch.ones((h, w), dtype=torch.float32)\n",
    "        y = torch.randint(h, (1,)).item()\n",
    "        x = torch.randint(w, (1,)).item()\n",
    "        y1 = max(0, y - self.length // 2)\n",
    "        y2 = min(h, y + self.length // 2)\n",
    "        x1 = max(0, x - self.length // 2)\n",
    "        x2 = min(w, x + self.length // 2)\n",
    "        img[:, y1:y2, x1:x2] = 0.0\n",
    "        return img\n",
    "\n",
    "# -----------------------------\n",
    "# Main\n",
    "# -----------------------------\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    cifar_mean = (0.4914, 0.4822, 0.4465)\n",
    "    cifar_std  = (0.2470, 0.2435, 0.2616)\n",
    "    \n",
    "    train_tfm = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(cifar_mean, cifar_std),\n",
    "        Cutout(length=8)\n",
    "    ])\n",
    "    test_tfm = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(cifar_mean, cifar_std)\n",
    "    ])\n",
    "    \n",
    "    train_ds = datasets.CIFAR10(\"./data\", train=True, download=True, transform=train_tfm)\n",
    "    test_ds  = datasets.CIFAR10(\"./data\", train=False, download=True, transform=test_tfm)\n",
    "    train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    test_loader  = DataLoader(test_ds, batch_size=256, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    epochs = 100\n",
    "    eta_values = [0.25]\n",
    "    K_limit = 1000\n",
    "    base_tolerance = 1e-6\n",
    "    lr_max = 0.035\n",
    "    lr_min = 0.0002\n",
    "    compare_every = 100  \n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    for eta in eta_values:\n",
    "        # --- ADAPTIVE TOLERANCE LOGIC ---\n",
    "        current_tol = 9e-5 if eta >= 0.9 else base_tolerance\n",
    "        \n",
    "        print(f\"\\n========================================\")\n",
    "        print(f\"Training CNN9 (eta={eta}, K={K_limit}, tol={current_tol})\")\n",
    "        print(f\"========================================\")\n",
    "        \n",
    "        W1 = kaiming_init((64, 3, 3, 3), device);   b1 = torch.zeros(64, device=device)\n",
    "        W2 = kaiming_init((64, 64, 3, 3), device);  b2 = torch.zeros(64, device=device)\n",
    "        W3 = kaiming_init((128, 64, 3, 3), device);  b3 = torch.zeros(128, device=device)\n",
    "        W4 = kaiming_init((128, 128, 3, 3), device); b4 = torch.zeros(128, device=device)\n",
    "        W5 = kaiming_init((256, 128, 3, 3), device); b5 = torch.zeros(256, device=device)\n",
    "        W6 = kaiming_init((256, 256, 3, 3), device); b6 = torch.zeros(256, device=device)\n",
    "        W7 = kaiming_init((512, 256, 3, 3), device); b7 = torch.zeros(512, device=device)\n",
    "        W8 = kaiming_init((512, 512, 3, 3), device); b8 = torch.zeros(512, device=device)\n",
    "        W9 = kaiming_init((10, 512*2*2), device);    b9 = torch.zeros(10, device=device)\n",
    "\n",
    "        net = CNN9(W1,b1,W2,b2,W3,b3,W4,b4,W5,b5,W6,b6,W7,b7,W8,b8,W9,b9)\n",
    "        ema_net = CNN9(W1.clone(),b1.clone(),W2.clone(),b2.clone(),W3.clone(),b3.clone(),\n",
    "                       W4.clone(),b4.clone(),W5.clone(),b5.clone(),W6.clone(),b6.clone(),\n",
    "                       W7.clone(),b7.clone(),W8.clone(),b8.clone(),W9.clone(),b9.clone())\n",
    "\n",
    "        vW = [torch.zeros_like(getattr(net, f\"W{i}\")) for i in range(1,10)]\n",
    "        vb = [torch.zeros_like(getattr(net, f\"b{i}\")) for i in range(1,10)]\n",
    "\n",
    "        total_steps = epochs * len(train_loader)\n",
    "        global_step = 0\n",
    "        state = XZState(64, device) \n",
    "        \n",
    "        # --- GLOBAL LOGGING LISTS ---\n",
    "        cos_globalW_hist = []\n",
    "        relerr_globalW_hist = []\n",
    "        norm_ratio_hist = [] \n",
    "        k_steps_hist = []\n",
    "        cos_steps = []\n",
    "        avg_steps_per_epoch = []\n",
    "        \n",
    "        # --- LAYER-WISE LOGGING LIST ---\n",
    "        # Format: List of dicts. Each dict has {step, layers: [{layer_id, cos, rel, true_norm, est_norm}, ...]}\n",
    "        layer_wise_metrics = []\n",
    "\n",
    "        for ep in range(1, epochs+1):\n",
    "            running_ce = 0.0\n",
    "            epoch_steps_accum = 0\n",
    "            num_batches = 0\n",
    "            \n",
    "            for i, (x, y) in enumerate(train_loader):\n",
    "                x = x.to(device, non_blocking=True)\n",
    "                y = y.to(device, non_blocking=True)\n",
    "                lr = cosine_lr(global_step, total_steps, lr_max=lr_max, lr_min=lr_min)\n",
    "\n",
    "                gradsW, gradsb, ce, steps_taken = xz_relax_batch_grad(\n",
    "                    net, x, y, eta=eta, K=K_limit, state=state, tol=current_tol, warm_start=True, beta=1.0\n",
    "                )\n",
    "                \n",
    "                # ---- LOGGING BLOCK EVERY 100 STEPS ----\n",
    "                if global_step % compare_every == 0:\n",
    "                    gradsW_ag, _, _ = autograd_grads_like_cnn9(net, x, y)\n",
    "                    \n",
    "                    # 1. Global Metrics (Flattened)\n",
    "                    gx = flat_cat(gradsW)\n",
    "                    ga = flat_cat(gradsW_ag)\n",
    "                    \n",
    "                    c_sim = cos_sim(gx, ga)\n",
    "                    r_err = relative_error(gx, ga)\n",
    "                    \n",
    "                    n_est = gx.norm().item()\n",
    "                    n_true = ga.norm().item()\n",
    "                    ratio = n_est / (n_true + 1e-12)\n",
    "                    \n",
    "                    cos_globalW_hist.append(c_sim)\n",
    "                    relerr_globalW_hist.append(r_err)\n",
    "                    norm_ratio_hist.append(ratio)\n",
    "                    k_steps_hist.append(steps_taken)\n",
    "                    cos_steps.append(global_step)\n",
    "                    \n",
    "                    # 2. Layer-wise Breakdown & True Norm Logging\n",
    "                    current_step_layer_stats = []\n",
    "                    \n",
    "                    # Loop W1 to W9\n",
    "                    for l_idx in range(9):\n",
    "                        g_est_l = gradsW[l_idx]\n",
    "                        g_true_l = gradsW_ag[l_idx]\n",
    "                        \n",
    "                        # Compute per-layer metrics\n",
    "                        l_cos = cos_sim(g_est_l, g_true_l)\n",
    "                        l_rel = relative_error(g_est_l, g_true_l)\n",
    "                        l_true_norm = g_true_l.norm().item()\n",
    "                        l_est_norm = g_est_l.norm().item()\n",
    "                        \n",
    "                        current_step_layer_stats.append({\n",
    "                            'layer': f\"W{l_idx+1}\",\n",
    "                            'cos_sim': l_cos,\n",
    "                            'rel_err': l_rel,\n",
    "                            'true_grad_norm': l_true_norm,  # |true|\n",
    "                            'est_grad_norm': l_est_norm     # |est|\n",
    "                        })\n",
    "                    \n",
    "                    # Store everything for post-processing\n",
    "                    layer_wise_metrics.append({\n",
    "                        'step': global_step,\n",
    "                        'layers': current_step_layer_stats\n",
    "                    })\n",
    "                    \n",
    "                    print(f\"[Step {global_step}] Global Cos: {c_sim:.4f} | Global RelErr: {r_err:.4f} | \"\n",
    "                          f\"NormRatio: {ratio:.4f} | W9 RelErr: {current_step_layer_stats[-1]['rel_err']:.4f} | Last K: {steps_taken}\")\n",
    "\n",
    "                sgd_momentum_step(net, gradsW, gradsb, vW, vb, lr=lr)\n",
    "                ema_update(ema_net, net, decay=0.999)\n",
    "\n",
    "                global_step += 1\n",
    "                running_ce += ce\n",
    "                epoch_steps_accum += steps_taken\n",
    "                num_batches += 1\n",
    "\n",
    "            test_acc = accuracy(ema_net, test_loader, device)\n",
    "            train_loss = running_ce / num_batches\n",
    "            avg_k = epoch_steps_accum / num_batches\n",
    "            avg_steps_per_epoch.append(avg_k)\n",
    "            print(f\">>> Ep {ep}: Loss {train_loss:.4f} | ACC {test_acc*100:.2f}% | Avg K: {avg_k:.1f}\")\n",
    "\n",
    "        results[eta] = {\n",
    "            'cos_globalW_hist': cos_globalW_hist,\n",
    "            'relerr_globalW_hist': relerr_globalW_hist,\n",
    "            'norm_ratio_hist': norm_ratio_hist,\n",
    "            'k_steps_hist': k_steps_hist,\n",
    "            'cos_steps': cos_steps,\n",
    "            'avg_steps_per_epoch': avg_steps_per_epoch,\n",
    "            'layer_wise_metrics': layer_wise_metrics\n",
    "        }\n",
    "\n",
    "    print(\"\\nSaving detailed results to experiment_data.pt ...\")\n",
    "    torch.save(results, \"experiment_data.pt\")\n",
    "    print(\"Data Saved.\")\n",
    "\n",
    "    print(\"Generating Plots...\")\n",
    "    plot_results_icml(results, eta_values)\n",
    "    plot_convergence_icml(results, eta_values)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8708de43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
